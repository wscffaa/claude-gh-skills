#!/usr/bin/env python3
"""
Experience Index: è‡ªåŠ¨æ£€ç´¢å†å²ç»éªŒ + ç»éªŒæ²‰æ·€

ä¸¤ç§æ¨¡å¼ï¼š
1. æ£€ç´¢æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰: ä»è§„åˆ™æ–‡ä»¶æ£€ç´¢åŒ¹é…çš„ç»éªŒ
2. æ²‰æ·€æ¨¡å¼ï¼ˆ--harvestï¼‰: ä»é¡¹ç›®äº§ç‰©ä¸­æå–æ–°ç»éªŒå¹¶æ›´æ–°è§„åˆ™æ–‡ä»¶

æ£€ç´¢æ¨¡å¼ Usage:
    python3 experience_index.py --scene "wavelet mamba" --project wavemamba --types wavelet,mamba
    python3 experience_index.py --scene "DCN å¯å˜å½¢" --project dcnmamba --types dcn --json

æ²‰æ·€æ¨¡å¼ Usage:
    python3 experience_index.py --harvest --project wavemamba
    python3 experience_index.py --harvest --project wavemamba --error "AMP ä¸ wavelet ä¸å…¼å®¹"
    python3 experience_index.py --harvest --project wavemamba --pattern "ä½¿ç”¨ autocast(enabled=False)"
"""

import argparse
import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional


# è§„åˆ™ç›®å½•ï¼ˆ.claude/rules/experience/ - Claude Code å®˜æ–¹è§„èŒƒï¼‰
RULES_DIR = Path(__file__).parent.parent.parent.parent / "rules" / "experience"


def load_rules(rule_file: str) -> list[dict]:
    """åŠ è½½å¹¶è§£æè§„åˆ™æ–‡ä»¶

    è§„åˆ™æ ¼å¼:
    ## è§„åˆ™ N: è§„åˆ™åç§°
    - è§¦å‘æ¡ä»¶: å…³é”®è¯ OR å…³é”®è¯
    - é£é™©ç­‰çº§: high | medium | low
    - æç¤ºä¿¡æ¯: é¢„è­¦ä¿¡æ¯
    - åŠ è½½æ–‡æ¡£: æ–‡æ¡£è·¯å¾„
    - å»ºè®®æœåŠ¡: æœåŠ¡1, æœåŠ¡2
    - æ¨¡å¼æ–‡ä»¶: æ¨¡å¼æ–‡ä»¶è·¯å¾„
    """
    path = RULES_DIR / rule_file
    if not path.exists():
        return []

    rules = []
    content = path.read_text(encoding="utf-8")

    # åŒ¹é…è§„åˆ™å—: ## è§„åˆ™ N: åç§° ... (åˆ°ä¸‹ä¸€ä¸ª ## è§„åˆ™ æˆ–æ–‡ä»¶ç»“æŸ)
    rule_pattern = r"## è§„åˆ™ (\d+|[A-Z]\d+): (.+?)\n([\s\S]+?)(?=\n## è§„åˆ™|\Z)"

    for match in re.finditer(rule_pattern, content):
        rule_id = match.group(1).strip()
        name = match.group(2).strip()
        body = match.group(3).strip()

        rule = {
            "id": rule_id,
            "name": name,
            "trigger": "",
            "files": [],
            "risk_level": "medium",
            "message": "",
            "services": [],
            "patterns": [],
        }

        for line in body.split("\n"):
            line = line.strip()
            if line.startswith("- è§¦å‘æ¡ä»¶:"):
                rule["trigger"] = line.replace("- è§¦å‘æ¡ä»¶:", "").strip()
            elif line.startswith("- åŠ è½½æ–‡æ¡£:"):
                rule["files"].append(line.replace("- åŠ è½½æ–‡æ¡£:", "").strip())
            elif line.startswith("- é£é™©ç­‰çº§:"):
                rule["risk_level"] = line.replace("- é£é™©ç­‰çº§:", "").strip()
            elif line.startswith("- æç¤ºä¿¡æ¯:"):
                rule["message"] = line.replace("- æç¤ºä¿¡æ¯:", "").strip()
            elif line.startswith("- å»ºè®®æœåŠ¡:"):
                services = line.replace("- å»ºè®®æœåŠ¡:", "").strip()
                rule["services"] = [s.strip() for s in services.split(",")]
            elif line.startswith("- æ¨¡å¼æ–‡ä»¶:"):
                rule["patterns"].append(line.replace("- æ¨¡å¼æ–‡ä»¶:", "").strip())

        rules.append(rule)

    return rules


def extract_keywords(trigger: str) -> list[str]:
    """ä»è§¦å‘æ¡ä»¶ä¸­æå–å…³é”®è¯

    è§¦å‘æ¡ä»¶æ ¼å¼: å…³é”®è¯1 OR å…³é”®è¯2 OR "å¤šè¯çŸ­è¯­"
    """
    keywords = []

    # å¤„ç†å¼•å·å†…çš„å¤šè¯çŸ­è¯­
    quoted = re.findall(r'"([^"]+)"', trigger)
    keywords.extend(quoted)

    # ç§»é™¤å¼•å·å†…å®¹åå¤„ç† OR åˆ†éš”çš„å…³é”®è¯
    remaining = re.sub(r'"[^"]+"', "", trigger)
    for part in remaining.split(" OR "):
        part = part.strip()
        if part and part.lower() not in ("or", "and"):
            keywords.append(part)

    return [kw.lower() for kw in keywords if kw]


def match_rules(rules: list[dict], scene: str, types: list[str]) -> list[dict]:
    """åŒ¹é…è§„åˆ™

    åŒ¹é…é€»è¾‘: åœºæ™¯æè¿°æˆ–åˆ›æ–°ç±»å‹ä¸­åŒ…å«ä»»ä¸€è§¦å‘å…³é”®è¯
    """
    matched = []
    search_text = scene.lower()
    type_keywords = [t.lower() for t in types]

    for rule in rules:
        trigger_keywords = extract_keywords(rule.get("trigger", ""))

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…
        for kw in trigger_keywords:
            if kw in search_text or kw in type_keywords or any(kw in t for t in type_keywords):
                matched.append(rule)
                break

    return matched


def experience_index(scene: str, project: str, types: list[str]) -> dict:
    """ä¸»æ£€ç´¢å‡½æ•°

    Args:
        scene: åœºæ™¯æè¿°
        project: é¡¹ç›® slug
        types: åˆ›æ–°ç±»å‹åˆ—è¡¨

    Returns:
        åŒ…å« context/risk/service/pattern å››ç±»ç»“æœçš„å­—å…¸
    """
    result = {
        "project": project,
        "scene": scene,
        "types": types,
        "context": {"files": []},
        "risk": {"alerts": []},
        "service": {"suggestions": []},
        "pattern": {"files": []},
    }

    # 1. åŠ è½½å¹¶åŒ¹é… context-rules
    context_rules = load_rules("context-rules.md")
    for rule in match_rules(context_rules, scene, types):
        result["context"]["files"].extend(rule.get("files", []))

    # 2. åŠ è½½å¹¶åŒ¹é… risk-rules
    risk_rules = load_rules("risk-rules.md")
    for rule in match_rules(risk_rules, scene, types):
        alert = {
            "level": rule.get("risk_level", "medium"),
            "error_id": f"E{rule.get('id', '000')}" if rule.get("id", "").isdigit() else rule.get("id", ""),
            "name": rule.get("name", ""),
            "message": rule.get("message", ""),
        }
        if alert["message"]:  # åªæ·»åŠ æœ‰æç¤ºä¿¡æ¯çš„
            result["risk"]["alerts"].append(alert)

    # 3. åŠ è½½å¹¶åŒ¹é… service-rules
    service_rules = load_rules("service-rules.md")
    for rule in match_rules(service_rules, scene, types):
        for svc in rule.get("services", []):
            suggestion = {
                "baseline": svc,
                "reason": rule.get("message", rule.get("name", "")),
            }
            result["service"]["suggestions"].append(suggestion)

    # 4. åŠ è½½å¹¶åŒ¹é… pattern-rules
    pattern_rules = load_rules("pattern-rules.md")
    for rule in match_rules(pattern_rules, scene, types):
        result["pattern"]["files"].extend(rule.get("patterns", []))

    # 5. å»é‡
    result["context"]["files"] = list(dict.fromkeys(result["context"]["files"]))
    result["pattern"]["files"] = list(dict.fromkeys(result["pattern"]["files"]))

    # 6. æŒ‰é£é™©ç­‰çº§æ’åº (high > medium > low)
    level_order = {"high": 0, "medium": 1, "low": 2}
    result["risk"]["alerts"].sort(key=lambda x: level_order.get(x["level"], 1))

    return result


def print_human_readable(result: dict) -> None:
    """è¾“å‡ºäººç±»å¯è¯»æ ¼å¼"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ç»éªŒæ£€ç´¢ç»“æœ: {result['project']}")
    print(f"   åœºæ™¯: {result['scene']}")
    if result["types"]:
        print(f"   ç±»å‹: {', '.join(result['types'])}")
    print(f"{'='*60}\n")

    # é£é™©é¢„è­¦
    if result["risk"]["alerts"]:
        print("âš ï¸  é£é™©é¢„è­¦:")
        for alert in result["risk"]["alerts"]:
            level_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(alert["level"], "âšª")
            error_id = f"[{alert['error_id']}] " if alert["error_id"] else ""
            print(f"   {level_icon} {error_id}{alert['message']}")
        print()

    # ä¸Šä¸‹æ–‡æ–‡æ¡£
    if result["context"]["files"]:
        print("ğŸ“š ç›¸å…³æ–‡æ¡£:")
        for f in result["context"]["files"]:
            print(f"   - {f}")
        print()

    # æœåŠ¡å»ºè®®
    if result["service"]["suggestions"]:
        print("ğŸ”§ Baseline/æœåŠ¡å»ºè®®:")
        for svc in result["service"]["suggestions"]:
            print(f"   - {svc['baseline']}: {svc['reason']}")
        print()

    # ä»£ç æ¨¡å¼
    if result["pattern"]["files"]:
        print("ğŸ“ æ¨èä»£ç æ¨¡å¼:")
        for f in result["pattern"]["files"]:
            print(f"   - {f}")
        print()

    # æ— ç»“æœæç¤º
    if not any([
        result["risk"]["alerts"],
        result["context"]["files"],
        result["service"]["suggestions"],
        result["pattern"]["files"],
    ]):
        print("â„¹ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„å†å²ç»éªŒ\n")


# ============================================================
# æ²‰æ·€æ¨¡å¼ (--harvest)
# ============================================================

def find_spec_dir(project: str) -> Optional[Path]:
    """æŸ¥æ‰¾é¡¹ç›® spec ç›®å½•"""
    specs_dir = Path("specs")
    if not specs_dir.exists():
        return None

    for d in specs_dir.iterdir():
        if d.is_dir() and f"proj-{project}" in d.name.lower():
            return d
    return None


def get_next_rule_id(rule_file: str) -> str:
    """è·å–ä¸‹ä¸€ä¸ªè§„åˆ™ ID"""
    path = RULES_DIR / rule_file
    if not path.exists():
        return "1"

    content = path.read_text(encoding="utf-8")
    ids = re.findall(r"## è§„åˆ™ (\d+):", content)
    if not ids:
        return "1"
    return str(max(int(i) for i in ids) + 1)


def extract_keywords_from_text(text: str) -> list[str]:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç”¨äºç”Ÿæˆè§¦å‘æ¡ä»¶ï¼‰"""
    # å¸¸è§çš„åˆ›æ–°ç±»å‹å…³é”®è¯
    known_keywords = [
        "wavelet", "å°æ³¢", "DWT", "IDWT", "pytorch_wavelets",
        "mamba", "ssm", "SS2D", "çŠ¶æ€ç©ºé—´",
        "DCN", "deformable", "å¯å˜å½¢", "åç§»é‡",
        "attention", "transformer", "æ³¨æ„åŠ›",
        "flow", "å…‰æµ", "RAFT", "å¯¹é½",
        "depth", "æ·±åº¦", "ZoeDepth",
        "AMP", "autocast", "æ··åˆç²¾åº¦",
        "é¢‘åŸŸ", "fourier", "fft",
        "è§†é¢‘", "video", "5D", "temporal",
    ]

    text_lower = text.lower()
    matched = []
    for kw in known_keywords:
        if kw.lower() in text_lower:
            matched.append(kw)

    return matched[:5]  # æœ€å¤š5ä¸ªå…³é”®è¯


def append_rule(rule_file: str, rule_id: str, name: str, trigger: str,
                message: str, level: str = None, file_path: str = None) -> bool:
    """è¿½åŠ è§„åˆ™åˆ°è§„åˆ™æ–‡ä»¶"""
    path = RULES_DIR / rule_file
    if not path.exists():
        return False

    # æ„å»ºè§„åˆ™å†…å®¹
    rule_content = f"\n## è§„åˆ™ {rule_id}: {name}\n"
    rule_content += f"- è§¦å‘æ¡ä»¶: {trigger}\n"
    if level:
        rule_content += f"- é£é™©ç­‰çº§: {level}\n"
    rule_content += f"- æç¤ºä¿¡æ¯: {message}\n"
    if file_path:
        if "risk" in rule_file:
            pass  # risk-rules ä¸éœ€è¦æ–‡ä»¶è·¯å¾„
        elif "pattern" in rule_file:
            rule_content += f"- æ¨¡å¼æ–‡ä»¶: {file_path}\n"
        elif "context" in rule_file:
            rule_content += f"- åŠ è½½æ–‡æ¡£: {file_path}\n"

    # è¿½åŠ åˆ°æ–‡ä»¶
    with open(path, "a", encoding="utf-8") as f:
        f.write(rule_content)

    return True


def scan_project_artifacts(spec_dir: Path) -> dict:
    """æ‰«æé¡¹ç›®äº§ç‰©ï¼Œæå–æ½œåœ¨çš„æ–°ç»éªŒ"""
    artifacts = {
        "errors": [],
        "patterns": [],
        "files_scanned": [],
    }

    # æ‰«æ error_report.md
    error_report = spec_dir / "debug" / "error_report.md"
    if error_report.exists():
        artifacts["files_scanned"].append(str(error_report))
        content = error_report.read_text(encoding="utf-8")
        # æå–é”™è¯¯æè¿°ï¼ˆç®€å•å¯å‘å¼ï¼‰
        for line in content.split("\n"):
            if "é”™è¯¯" in line or "Error" in line or "å¤±è´¥" in line:
                artifacts["errors"].append(line.strip()[:200])

    # æ‰«æ backprop_log.md
    backprop_log = spec_dir / "backprop" / "backprop_log.md"
    if backprop_log.exists():
        artifacts["files_scanned"].append(str(backprop_log))
        content = backprop_log.read_text(encoding="utf-8")
        # æå–ä¿®å¤æ¨¡å¼
        for line in content.split("\n"):
            if "ä¿®å¤" in line or "è§£å†³" in line or "æ–¹æ¡ˆ" in line:
                artifacts["patterns"].append(line.strip()[:200])

    return artifacts


def harvest_experience(project: str, error: str = None, pattern: str = None) -> dict:
    """æ²‰æ·€ç»éªŒä¸»å‡½æ•°

    Args:
        project: é¡¹ç›® slug
        error: æ‰‹åŠ¨æŒ‡å®šçš„é”™è¯¯æè¿°
        pattern: æ‰‹åŠ¨æŒ‡å®šçš„æ¨¡å¼æè¿°

    Returns:
        æ²‰æ·€æŠ¥å‘Š
    """
    report = {
        "project": project,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "spec_dir": None,
        "rules_added": {
            "risk": [],
            "pattern": [],
            "context": [],
        },
        "skipped": [],
        "leanspec_synced": False,
    }

    # æŸ¥æ‰¾ spec ç›®å½•
    spec_dir = find_spec_dir(project)
    if spec_dir:
        report["spec_dir"] = str(spec_dir)

    # æ‰‹åŠ¨è®°å½•é”™è¯¯
    if error:
        keywords = extract_keywords_from_text(error)
        if keywords:
            trigger = " OR ".join(keywords)
            rule_id = get_next_rule_id("risk-rules.md")
            name = f"æ¥è‡ª {project} çš„é”™è¯¯"

            if append_rule("risk-rules.md", rule_id, name, trigger, error, level="high"):
                report["rules_added"]["risk"].append({
                    "id": rule_id,
                    "name": name,
                    "trigger": trigger,
                    "message": error,
                })
        else:
            report["skipped"].append(f"æ— æ³•ä»é”™è¯¯æè¿°ä¸­æå–å…³é”®è¯: {error[:50]}...")

    # æ‰‹åŠ¨è®°å½•æ¨¡å¼
    if pattern:
        keywords = extract_keywords_from_text(pattern)
        if keywords:
            trigger = " OR ".join(keywords)
            rule_id = get_next_rule_id("pattern-rules.md")
            name = f"æ¥è‡ª {project} çš„æ¨¡å¼"

            if append_rule("pattern-rules.md", rule_id, name, trigger, pattern):
                report["rules_added"]["pattern"].append({
                    "id": rule_id,
                    "name": name,
                    "trigger": trigger,
                    "message": pattern,
                })
        else:
            report["skipped"].append(f"æ— æ³•ä»æ¨¡å¼æè¿°ä¸­æå–å…³é”®è¯: {pattern[:50]}...")

    # è‡ªåŠ¨æ‰«æï¼ˆå¦‚æœæ²¡æœ‰æ‰‹åŠ¨æŒ‡å®šï¼‰
    if not error and not pattern and spec_dir:
        artifacts = scan_project_artifacts(spec_dir)
        report["files_scanned"] = artifacts["files_scanned"]

        # ç›®å‰åªæŠ¥å‘Šå‘ç°ï¼Œä¸è‡ªåŠ¨æ·»åŠ ï¼ˆé¿å…å™ªéŸ³ï¼‰
        if artifacts["errors"]:
            report["potential_errors"] = artifacts["errors"][:3]
        if artifacts["patterns"]:
            report["potential_patterns"] = artifacts["patterns"][:3]

    # å¦‚æœæœ‰æ–°å¢è§„åˆ™ï¼Œè§¦å‘ lean-spec åŒæ­¥
    if any(report["rules_added"].values()):
        try:
            sync_to_leanspec()
            report["leanspec_synced"] = True
        except Exception as e:
            report["leanspec_sync_error"] = str(e)

    return report


def sync_to_leanspec() -> None:
    """è§¦å‘ lean-spec åŒæ­¥è„šæœ¬"""
    import subprocess
    sync_script = Path(__file__).parent.parent.parent.parent / "scripts" / "sync_error_to_leanspec.py"
    if sync_script.exists():
        subprocess.run(["python3", str(sync_script)], check=True, capture_output=True)


def print_harvest_report(report: dict) -> None:
    """è¾“å‡ºæ²‰æ·€æŠ¥å‘Š"""
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ ç»éªŒæ²‰æ·€æŠ¥å‘Š: {report['project']}")
    print(f"   æ—¶é—´: {report['timestamp']}")
    if report.get("spec_dir"):
        print(f"   Spec: {report['spec_dir']}")
    print(f"{'='*60}\n")

    # æ–°å¢è§„åˆ™
    has_new = False
    for rule_type, rules in report["rules_added"].items():
        if rules:
            has_new = True
            type_name = {"risk": "é£é™©è§„åˆ™", "pattern": "æ¨¡å¼è§„åˆ™", "context": "ä¸Šä¸‹æ–‡è§„åˆ™"}.get(rule_type, rule_type)
            print(f"âœ… æ–°å¢ {type_name}:")
            for r in rules:
                print(f"   - è§„åˆ™ {r['id']}: {r['name']}")
                print(f"     è§¦å‘: {r['trigger']}")
                print(f"     å†…å®¹: {r['message'][:80]}...")
            print()

    # è·³è¿‡çš„
    if report.get("skipped"):
        print("â­ï¸  è·³è¿‡:")
        for s in report["skipped"]:
            print(f"   - {s}")
        print()

    # æ½œåœ¨å‘ç°ï¼ˆè‡ªåŠ¨æ‰«æç»“æœï¼‰
    if report.get("potential_errors"):
        print("ğŸ” å‘ç°æ½œåœ¨é”™è¯¯ï¼ˆéœ€æ‰‹åŠ¨ç¡®è®¤åæ²‰æ·€ï¼‰:")
        for e in report["potential_errors"]:
            print(f"   - {e[:80]}...")
        print("   ä½¿ç”¨: --error \"<æè¿°>\" æ‰‹åŠ¨æ²‰æ·€")
        print()

    if report.get("potential_patterns"):
        print("ğŸ” å‘ç°æ½œåœ¨æ¨¡å¼ï¼ˆéœ€æ‰‹åŠ¨ç¡®è®¤åæ²‰æ·€ï¼‰:")
        for p in report["potential_patterns"]:
            print(f"   - {p[:80]}...")
        print("   ä½¿ç”¨: --pattern \"<æè¿°>\" æ‰‹åŠ¨æ²‰æ·€")
        print()

    # lean-spec åŒæ­¥çŠ¶æ€
    if report.get("leanspec_synced"):
        print("ğŸ“¦ lean-spec åŒæ­¥: âœ… å·²åŒæ­¥åˆ° specs/5xx-std-error-*")
        print()
    elif report.get("leanspec_sync_error"):
        print(f"ğŸ“¦ lean-spec åŒæ­¥: âŒ å¤±è´¥ - {report['leanspec_sync_error']}")
        print()

    if not has_new and not report.get("potential_errors") and not report.get("potential_patterns"):
        print("â„¹ï¸  æ— æ–°ç»éªŒéœ€è¦æ²‰æ·€\n")


def main():
    parser = argparse.ArgumentParser(
        description="Experience Index: è‡ªåŠ¨æ£€ç´¢å†å²ç»éªŒ + ç»éªŒæ²‰æ·€",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ£€ç´¢æ¨¡å¼
  python3 experience_index.py --scene "wavelet å°æ³¢å˜æ¢" --project wavemamba --types wavelet

  # æ²‰æ·€æ¨¡å¼ - è‡ªåŠ¨æ‰«æ
  python3 experience_index.py --harvest --project wavemamba

  # æ²‰æ·€æ¨¡å¼ - è®°å½•é”™è¯¯
  python3 experience_index.py --harvest --project wavemamba --error "AMP ä¸ wavelet ä¸å…¼å®¹"

  # æ²‰æ·€æ¨¡å¼ - è®°å½•æ¨¡å¼
  python3 experience_index.py --harvest --project wavemamba --pattern "ä½¿ç”¨ autocast(enabled=False)"
        """,
    )

    # æ¨¡å¼é€‰æ‹©
    parser.add_argument("--harvest", action="store_true", help="æ²‰æ·€æ¨¡å¼ï¼šä»é¡¹ç›®äº§ç‰©æå–ç»éªŒ")

    # æ£€ç´¢æ¨¡å¼å‚æ•°
    parser.add_argument("--scene", help="åœºæ™¯æè¿°ï¼ˆæ£€ç´¢æ¨¡å¼å¿…éœ€ï¼‰")
    parser.add_argument("--types", default="", help="åˆ›æ–°ç±»å‹ï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--json", action="store_true", help="è¾“å‡º JSON æ ¼å¼")

    # å…±ç”¨å‚æ•°
    parser.add_argument("--project", help="é¡¹ç›® slugï¼ˆä¸¤ç§æ¨¡å¼éƒ½éœ€è¦ï¼‰")

    # æ²‰æ·€æ¨¡å¼å‚æ•°
    parser.add_argument("--error", help="æ‰‹åŠ¨è®°å½•é”™è¯¯æè¿°ï¼ˆæ²‰æ·€æ¨¡å¼ï¼‰")
    parser.add_argument("--pattern", help="æ‰‹åŠ¨è®°å½•æ¨¡å¼æè¿°ï¼ˆæ²‰æ·€æ¨¡å¼ï¼‰")

    args = parser.parse_args()

    # æ²‰æ·€æ¨¡å¼
    if args.harvest:
        if not args.project:
            parser.error("--harvest æ¨¡å¼éœ€è¦ --project å‚æ•°")

        report = harvest_experience(args.project, args.error, args.pattern)

        if args.json:
            print(json.dumps(report, ensure_ascii=False, indent=2))
        else:
            print_harvest_report(report)
        return

    # æ£€ç´¢æ¨¡å¼
    if not args.scene:
        parser.error("æ£€ç´¢æ¨¡å¼éœ€è¦ --scene å‚æ•°")
    if not args.project:
        parser.error("æ£€ç´¢æ¨¡å¼éœ€è¦ --project å‚æ•°")

    # è§£æç±»å‹
    types = [t.strip() for t in args.types.split(",") if t.strip()]

    # æ‰§è¡Œæ£€ç´¢
    result = experience_index(args.scene, args.project, types)

    # è¾“å‡ºç»“æœ
    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print_human_readable(result)


if __name__ == "__main__":
    main()
