#!/usr/bin/env python3
"""
æ ¹æ® priority_batcher.py --json çš„è¾“å‡ºï¼ŒæŒ‰æ‰¹æ¬¡å¹¶å‘æ‰§è¡Œ issueã€‚

åŠŸèƒ½:
- ä» stdin æˆ– --input æ–‡ä»¶è¯»å– JSONï¼ˆpriority_batcher.py --json è¾“å‡ºï¼‰
- æ¯æ‰¹æ¬¡å†…æ”¯æŒå¹¶å‘æ‰§è¡Œï¼ˆDAG è°ƒåº¦ï¼Œä¾èµ–æ„ŸçŸ¥ï¼‰
- è‡ªé€‚åº”å¹¶å‘æ•°ï¼šæ ¹æ®ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»åŠ¨æ€è°ƒæ•´
  - P0: max_workers=4ï¼ˆç´§æ€¥ï¼Œé«˜å¹¶å‘ï¼‰
  - P1: max_workers=3
  - P2: max_workers=2
  - P3: max_workers=1
  - æœ‰ä¾èµ–æ—¶å¹¶å‘æ•° -1
- å¤ç”¨ worktree.py è„šæœ¬è¿›è¡Œ worktree ç®¡ç†ï¼ˆåŒç›®å½•ä¸‹çš„ worktree.pyï¼‰
- æ¯ä¸ª issue åˆ›å»ºç‹¬ç«‹ worktree: {repo}-worktrees/issue-{number}
- ä½¿ç”¨ codeagent-wrapper æ‰§è¡Œå•ä¸ª issueï¼ˆstdin ä¼ å…¥ä»»åŠ¡è¯´æ˜ï¼‰
- å¤±è´¥æ”¯æŒé‡è¯•ï¼šæ¸…ç† worktree ä¸è¿œç¨‹åˆ†æ”¯åé‡è¯•ï¼ˆ--max-retriesï¼‰
- è‹¥æ£€æµ‹åˆ°å¯¹åº” PRï¼ˆhead=issue-{number}ï¼‰ï¼Œè‡ªåŠ¨æ‰§è¡Œ PR Reviewï¼ˆcodeagent-wrapper --backend codexï¼‰å¹¶åˆå¹¶ï¼ˆgh pr merge --squash --delete-branchï¼‰
- issue å®Œæˆåè‡ªåŠ¨æ¸…ç† worktree
- Ctrl+Cï¼ˆSIGINTï¼‰æ—¶æ¸…ç†å½“å‰ worktree å¹¶è¾“å‡ºå·²å®ŒæˆæŠ¥å‘Š

è¾“å‡ºæ ¼å¼:
- å¼€å§‹å¤„ç†: ğŸš€ å¼€å§‹å¤„ç† (å…± {total} ä¸ª issues)
- æ¯ä¸ªæ‰¹æ¬¡å¼€å§‹: ğŸ“¦ {PRIORITY} æ‰¹æ¬¡ ({count} issues, å¹¶å‘={workers})
- æ¯ä¸ª issue å¼€å§‹: [2/10] æ­£åœ¨å¤„ç† Issue #42: xxx (P1)
- æ¯ä¸ª issue å®Œæˆ: âœ… Issue #42 å·²å®Œæˆï¼ŒPR #123 å·²åˆå¹¶ (è€—æ—¶ 2m30s)
- æ¯ä¸ª issue å¤±è´¥: âŒ Issue #42 å¤±è´¥ (å°è¯• 2/4): xxx
- æ¯ä¸ªæ‰¹æ¬¡å®Œæˆ: ğŸ“¦ {PRIORITY} æ‰¹æ¬¡å®Œæˆ ({completed}/{total})
- æœ€ç»ˆè¾“å‡ºå®ŒæˆæŠ¥å‘Š
"""

from __future__ import annotations

import argparse
import asyncio
import json
import re
import shlex
import signal
import subprocess
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from pathlib import Path
from threading import Lock
from typing import Any, Optional, TextIO

# å¯¼å…¥å®‰å…¨å‘½ä»¤æ„é€ æ¨¡å—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from safe_command import (
        SafeCommandBuilder,
        run_command_with_stdin,
        build_codeagent_command,
        escape_for_logging,
    )
    HAS_SAFE_COMMAND = True
except ImportError:
    HAS_SAFE_COMMAND = False


DEFAULT_WORKTREE_SCRIPT = Path(__file__).parent / "worktree.py"
SESSION_ID_PATTERN = re.compile(r"\bSESSION_ID\s*[:=]\s*([A-Za-z0-9._-]+)")
ISSUE_BRANCH_PATTERN = re.compile(r"\bissue-(\d+)\b")


@dataclass
class IssueSpec:
    number: int
    priority: str
    title: str = ""
    dependencies: list[int] = field(default_factory=list)


@dataclass
class IssueResult:
    number: int
    priority: str
    title: str
    status: str  # completed | failed | interrupted | skipped
    pr_number: Optional[int] = None  # PR ç¼–å·
    elapsed_sec: float = 0.0  # è€—æ—¶ï¼ˆç§’ï¼‰
    attempts: int = 1
    returncode: Optional[int] = None
    detail: str = ""


@dataclass
class ExecState:
    interrupted: bool = False
    current_issue: Optional[int] = None
    current_worktree_path: Optional[Path] = None
    current_process: Optional[subprocess.Popen] = None
    last_process: Optional[subprocess.Popen] = None
    session_ids: dict[int, str] = field(default_factory=dict)
    # èµ„æºè¿½è¸ªï¼šç”¨äº finally é˜¶æ®µç»Ÿä¸€æ¸…ç†
    created_issues: set[int] = field(default_factory=set)
    # å¹¶å‘æ‰§è¡Œç›¸å…³
    active_issues: set[int] = field(default_factory=set)
    active_processes: dict[int, subprocess.Popen] = field(default_factory=dict)
    active_worktrees: dict[int, Path] = field(default_factory=dict)
    lock: Lock = field(default_factory=Lock)


@dataclass
class CleanupReport:
    tracked_issues: list[int] = field(default_factory=list)
    worktree_removed: dict[int, tuple[bool, str]] = field(default_factory=dict)
    worktree_force_used: set[int] = field(default_factory=set)
    local_branch_deleted: dict[int, tuple[bool, str]] = field(default_factory=dict)
    remote_branch_deleted: dict[int, tuple[bool, str]] = field(default_factory=dict)
    prune_ok: bool = False
    prune_detail: str = ""


# ==================== è‡ªé€‚åº”å¹¶å‘æ•°è®¡ç®— ====================

def _calculate_max_workers(priority: str, batch_size: int, has_dependencies: bool) -> int:
    """
    æ ¹æ®ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»è®¡ç®—æœ€å¤§å¹¶å‘æ•°ã€‚

    è§„åˆ™ï¼š
    - P0: åŸºç¡€å¹¶å‘æ•° 4ï¼ˆç´§æ€¥ä»»åŠ¡ï¼Œå°½å¿«å®Œæˆï¼‰
    - P1: åŸºç¡€å¹¶å‘æ•° 3
    - P2: åŸºç¡€å¹¶å‘æ•° 2
    - P3: åŸºç¡€å¹¶å‘æ•° 1ï¼ˆä½ä¼˜å…ˆçº§ï¼ŒèŠ‚çœèµ„æºï¼‰
    - æœ‰ä¾èµ–æ—¶ï¼šå¹¶å‘æ•° -1ï¼ˆé¿å…è¿‡å¤šç­‰å¾…ï¼‰
    - æœ€ç»ˆå– min(base, batch_size)
    """
    base = {
        "p0": 4,
        "p1": 3,
        "p2": 2,
        "p3": 1,
    }.get(priority.lower(), 2)

    if has_dependencies:
        base = max(1, base - 1)

    return max(1, min(base, batch_size))


# ==================== DAG è°ƒåº¦å™¨ ====================

class DagScheduler:
    """
    ä¾èµ–æ„ŸçŸ¥çš„ DAG è°ƒåº¦å™¨ã€‚

    - ç»´æŠ¤ pending/in_progress/completed ä¸‰ä¸ªçŠ¶æ€é›†åˆ
    - get_ready_issues() è¿”å›æ‰€æœ‰ä¾èµ–å·²å®Œæˆçš„å¾…å¤„ç† issue
    - æ”¯æŒå¹¶å‘è°ƒç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    """

    def __init__(self, specs: list[IssueSpec]):
        self.specs = {s.number: s for s in specs}
        self.completed: set[int] = set()
        self.failed: set[int] = set()
        self.in_progress: set[int] = set()
        self.pending: set[int] = set(s.number for s in specs)
        self._lock = Lock()

    def get_ready_issues(self) -> list[int]:
        """è¿”å›æ‰€æœ‰ä¾èµ–å·²å®Œæˆä¸”æœªå¼€å§‹çš„ issue ç¼–å·"""
        with self._lock:
            ready = []
            for num in list(self.pending):
                spec = self.specs[num]
                # ä¾èµ–å¿…é¡»å…¨éƒ¨å®Œæˆï¼ˆä¸å«å¤±è´¥ï¼‰
                deps_met = all(
                    dep in self.completed
                    for dep in spec.dependencies
                    if dep in self.specs
                )
                if deps_met:
                    ready.append(num)
            return ready

    def mark_started(self, num: int) -> bool:
        """æ ‡è®° issue ä¸ºè¿›è¡Œä¸­ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        with self._lock:
            if num not in self.pending:
                return False
            self.pending.discard(num)
            self.in_progress.add(num)
            return True

    def mark_completed(self, num: int):
        """æ ‡è®° issue ä¸ºå·²å®Œæˆ"""
        with self._lock:
            self.in_progress.discard(num)
            self.completed.add(num)

    def mark_failed(self, num: int):
        """æ ‡è®° issue ä¸ºå¤±è´¥"""
        with self._lock:
            self.in_progress.discard(num)
            self.failed.add(num)

    def is_done(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ issue éƒ½å·²å¤„ç†"""
        with self._lock:
            return len(self.pending) == 0 and len(self.in_progress) == 0

    def has_blocked_issues(self) -> list[int]:
        """è¿”å›å› ä¾èµ–å¤±è´¥è€Œè¢«é˜»å¡çš„ issue"""
        with self._lock:
            blocked = []
            for num in list(self.pending):
                spec = self.specs[num]
                # å¦‚æœä»»ä¸€ä¾èµ–å¤±è´¥ï¼Œåˆ™è¯¥ issue è¢«é˜»å¡
                if any(dep in self.failed for dep in spec.dependencies if dep in self.specs):
                    blocked.append(num)
            return blocked


def _read_json_input(path: Optional[str]) -> dict[str, Any]:
    if path and path != "-":
        try:
            raw = Path(path).read_text(encoding="utf-8")
        except OSError as e:
            print(f"Error: è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        if sys.stdin.isatty():
            print("Error: æœªæä¾›è¾“å…¥ï¼Œè¯·é€šè¿‡ stdin ç®¡é“æˆ– --input æŒ‡å®š JSON æ–‡ä»¶", file=sys.stderr)
            sys.exit(1)
        raw = sys.stdin.read()

    try:
        data = json.loads(raw)
    except json.JSONDecodeError as e:
        print(f"Error: JSON è§£æå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    if not isinstance(data, dict):
        print("Error: è¾“å…¥ JSON é¡¶å±‚å¿…é¡»ä¸ºå¯¹è±¡ï¼ˆåŒ…å« batches å­—æ®µï¼‰", file=sys.stderr)
        sys.exit(1)
    return data


def _extract_specs(data: dict[str, Any]) -> tuple[list[IssueSpec], list[str]]:
    """
    ä» priority_batcher.py --json è¾“å‡ºä¸­æå– IssueSpec åˆ—è¡¨ã€‚

    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. æ–°æ ¼å¼ï¼ˆæ¨èï¼‰ï¼šissues ä¸ºå¯¹è±¡æ•°ç»„
       {"number": 42, "title": "xxx", "dependencies": [41]}
    2. æ—§æ ¼å¼ï¼ˆå…¼å®¹ï¼‰ï¼šissues ä¸ºæ•´æ•°æ•°ç»„
       [42, 43, 44]
    """
    batches = data.get("batches")
    if not isinstance(batches, list):
        print("Error: è¾“å…¥ JSON ç¼ºå°‘ batches åˆ—è¡¨ï¼ˆpriority_batcher.py --json è¾“å‡ºï¼‰", file=sys.stderr)
        sys.exit(1)

    warnings: list[str] = []
    specs: list[IssueSpec] = []
    seen: set[int] = set()

    for batch in batches:
        if not isinstance(batch, dict):
            continue
        priority = str(batch.get("priority", "")).strip().lower()
        raw_issues = batch.get("issues")
        if not isinstance(raw_issues, list):
            continue
        for raw in raw_issues:
            number: Optional[int] = None
            title: str = ""
            dependencies: list[int] = []

            # æ–°æ ¼å¼ï¼šå¯¹è±¡
            if isinstance(raw, dict):
                number = raw.get("number")
                if not isinstance(number, int):
                    continue
                title = str(raw.get("title", ""))
                raw_deps = raw.get("dependencies", [])
                if isinstance(raw_deps, list):
                    dependencies = [d for d in raw_deps if isinstance(d, int)]
            # æ—§æ ¼å¼ï¼šæ•´æ•°
            elif isinstance(raw, int):
                number = raw
            elif isinstance(raw, str) and raw.strip().isdigit():
                number = int(raw.strip())

            if not number or number <= 0:
                continue
            if number in seen:
                warnings.append(f"é‡å¤ issue: #{number} å·²è·³è¿‡é‡å¤æ¡ç›®")
                continue
            seen.add(number)
            specs.append(IssueSpec(
                number=number,
                priority=priority or "p2",
                title=title,
                dependencies=dependencies,
            ))

    return specs, warnings


def _open_tty_stdin() -> Optional[TextIO]:
    if sys.stdin.isatty():
        return None
    try:
        return open("/dev/tty", "r")
    except OSError:
        return None


def _run_gh_issue_title(issue_number: int, repo: Optional[str], cwd: Path) -> str:
    cmd = ["gh", "issue", "view", str(issue_number)]
    if repo:
        cmd += ["--repo", repo]
    cmd += ["--json", "title", "-q", ".title"]

    for attempt in range(2):
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=20, cwd=str(cwd))
        except subprocess.TimeoutExpired:
            if attempt == 0:
                continue
            return ""
        except FileNotFoundError:
            return ""
        except Exception:
            return ""

        if result.returncode == 0:
            return (result.stdout or "").strip()
        if attempt == 0:
            continue
        return ""

    return ""


def _last_nonempty_line(text: str) -> str:
    lines = [ln.strip() for ln in (text or "").splitlines() if ln.strip()]
    return lines[-1] if lines else ""


def _parse_session_id(text: str) -> Optional[str]:
    if not text:
        return None
    matches = SESSION_ID_PATTERN.findall(text)
    if not matches:
        return None
    return matches[-1]


def _stop_process(proc: subprocess.Popen, timeout_sec: float = 5.0) -> None:
    if proc.poll() is not None:
        return
    try:
        proc.send_signal(signal.SIGINT)
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
        return
    except subprocess.TimeoutExpired:
        pass

    try:
        proc.terminate()
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
        return
    except subprocess.TimeoutExpired:
        pass

    try:
        proc.kill()
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
    except Exception:
        pass


def _run_capture(cmd: list[str], cwd: Path, state: ExecState) -> subprocess.CompletedProcess[str]:
    try:
        proc = subprocess.Popen(cmd, cwd=str(cwd), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    except FileNotFoundError as e:
        return subprocess.CompletedProcess(cmd, 127, "", str(e))

    state.current_process = proc
    state.last_process = proc
    try:
        stdout, stderr = proc.communicate()
    finally:
        state.current_process = None

    return subprocess.CompletedProcess(cmd, proc.returncode, stdout, stderr)


def _create_worktree(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> Path:
    result = _run_capture(["python3", str(script_path), "create", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode != 0:
        detail = (result.stderr or "").strip() or (result.stdout or "").strip()
        raise RuntimeError(detail or f"worktree create å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰")

    path_str = _last_nonempty_line(result.stdout)
    if not path_str:
        probe = _run_capture(["python3", str(script_path), "path", str(issue_number)], cwd=repo_dir, state=state)
        if probe.returncode == 0:
            path_str = (probe.stdout or "").strip()

    if not path_str:
        raise RuntimeError("æ— æ³•è§£æ worktree è·¯å¾„")
    return Path(path_str)


def _remove_worktree(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    result = _run_capture(["python3", str(script_path), "remove", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    return False, detail or f"worktree remove å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _get_worktree_path(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> Optional[Path]:
    result = _run_capture(["python3", str(script_path), "path", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode != 0:
        return None
    path_str = (result.stdout or "").strip()
    return Path(path_str) if path_str else None


def _force_remove_worktree(issue_number: int, worktree_path: Path, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    result = _run_capture(
        ["git", "worktree", "remove", "--force", str(worktree_path)],
        cwd=repo_dir,
        state=state,
    )
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    detail = detail or f"git worktree remove --force å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"
    return False, detail


def _cleanup_remote_branch(issue_number: int, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    branch = f"issue-{issue_number}"
    result = _run_capture(["git", "push", "origin", "--delete", branch], cwd=repo_dir, state=state)
    if result.returncode == 0:
        return True, ""

    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    detail_lower = detail.lower()
    if "remote ref does not exist" in detail_lower:
        return True, ""

    return False, detail or f"git push origin --delete {branch} å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _cleanup_local_branch(issue_number: int, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    branch = f"issue-{issue_number}"
    result = _run_capture(["git", "branch", "-D", branch], cwd=repo_dir, state=state)
    if result.returncode == 0:
        return True, ""

    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    detail_lower = detail.lower()
    if "not found" in detail_lower and "branch" in detail_lower:
        return True, ""

    return False, detail or f"git branch -D {branch} å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _cleanup_all_resources(state: ExecState, repo_dir: Path, worktree_script: Path) -> CleanupReport:
    report = CleanupReport()
    with state.lock:
        issue_numbers = sorted(state.created_issues)
        active_worktrees = dict(state.active_worktrees)

    report.tracked_issues = issue_numbers

    for issue_number in issue_numbers:
        # 1) åˆ é™¤ worktreeï¼ˆå¤±è´¥åˆ™ --forceï¼‰
        worktree_ok, worktree_detail = _remove_worktree(worktree_script, issue_number, repo_dir, state)
        worktree_detail_lower = (worktree_detail or "").lower()
        if not worktree_ok and "worktree not found" in worktree_detail_lower:
            worktree_ok, worktree_detail = True, ""

        if not worktree_ok:
            worktree_path = _get_worktree_path(worktree_script, issue_number, repo_dir, state)
            if not worktree_path:
                worktree_path = active_worktrees.get(issue_number)
            if worktree_path:
                report.worktree_force_used.add(issue_number)
                ok2, detail2 = _force_remove_worktree(issue_number, worktree_path, repo_dir, state)
                if ok2:
                    worktree_ok, worktree_detail = True, ""
                else:
                    merged = "; ".join(x for x in [worktree_detail, detail2] if x)
                    worktree_ok, worktree_detail = False, merged or worktree_detail or detail2

        report.worktree_removed[issue_number] = (worktree_ok, worktree_detail)

        # 2) åˆ é™¤æœ¬åœ°åˆ†æ”¯
        lb_ok, lb_detail = _cleanup_local_branch(issue_number, repo_dir, state)
        report.local_branch_deleted[issue_number] = (lb_ok, lb_detail)

        # 3) åˆ é™¤è¿œç«¯åˆ†æ”¯
        rb_ok, rb_detail = _cleanup_remote_branch(issue_number, repo_dir, state)
        report.remote_branch_deleted[issue_number] = (rb_ok, rb_detail)

    # 4) æ‰§è¡Œ git worktree prune
    prune = _run_capture(["git", "worktree", "prune"], cwd=repo_dir, state=state)
    if prune.returncode == 0:
        report.prune_ok = True
        report.prune_detail = ""
    else:
        detail = (prune.stderr or "").strip() or (prune.stdout or "").strip()
        report.prune_ok = False
        report.prune_detail = detail or f"git worktree prune å¤±è´¥ï¼ˆexit={prune.returncode}ï¼‰"

    return report


def _build_task_content(issue_number: int, title: str) -> str:
    """
    æ„å»ºä»»åŠ¡å†…å®¹ï¼Œç¡®ä¿ç‰¹æ®Šå­—ç¬¦å®‰å…¨å¤„ç†ã€‚

    Args:
        issue_number: Issue ç¼–å·
        title: Issue æ ‡é¢˜

    Returns:
        æ ¼å¼åŒ–çš„ä»»åŠ¡å†…å®¹å­—ç¬¦ä¸²
    """
    # å¯¹æ ‡é¢˜è¿›è¡Œå®‰å…¨å¤„ç†ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„æ§åˆ¶å­—ç¬¦
    safe_title = title.replace("\r", "").replace("\0", "")

    return (
        f"å®ç° Issue #{issue_number}: {safe_title}\n\n"
        "Requirements:\n"
        "- å‚è€ƒ issue æè¿°å®Œæˆå¼€å‘ä»»åŠ¡\n"
        f"- åˆ›å»º issue-{issue_number} åˆ†æ”¯\n"
        "- æäº¤ä»£ç å¹¶åˆ›å»º PR\n\n"
        "Deliverables:\n"
        "- ä»£ç å®ç°\n"
        "- å•å…ƒæµ‹è¯•\n"
        f"- åˆ›å»º PR (åˆ†æ”¯å: issue-{issue_number})\n"
    )


def _build_codeagent_cmd(backend: str = "codex") -> list[str]:
    """
    ä½¿ç”¨å®‰å…¨æ–¹å¼æ„å»º codeagent-wrapper å‘½ä»¤ã€‚

    Args:
        backend: åç«¯ç±»å‹

    Returns:
        å‘½ä»¤å‚æ•°åˆ—è¡¨
    """
    if HAS_SAFE_COMMAND:
        builder = build_codeagent_command(backend=backend, use_stdin=True)
        return builder.build()
    else:
        # å›é€€åˆ°ç›´æ¥åˆ—è¡¨æ„é€ ï¼ˆä»ç„¶å®‰å…¨ï¼Œå› ä¸ºä¸ç»è¿‡ shellï¼‰
        return ["codeagent-wrapper", "--backend", shlex.quote(backend), "-"]


def _run_claude(issue_number: int, title: str, worktree_path: Path, state: ExecState) -> int:
    """
    ä½¿ç”¨ codeagent-wrapper æ‰§è¡Œ Issue å®ç°ä»»åŠ¡ã€‚

    é€šè¿‡ stdin ä¼ é€’ä»»åŠ¡å†…å®¹ï¼Œé¿å… heredoc å’Œç‰¹æ®Šå­—ç¬¦é—®é¢˜ã€‚

    Args:
        issue_number: Issue ç¼–å·
        title: Issue æ ‡é¢˜
        worktree_path: worktree è·¯å¾„
        state: æ‰§è¡ŒçŠ¶æ€

    Returns:
        è¿›ç¨‹è¿”å›ç 
    """
    task_content = _build_task_content(issue_number, title)

    # ä½¿ç”¨åˆ—è¡¨æ¨¡å¼æ„é€ å‘½ä»¤ï¼Œé¿å… shell è§£æ
    cmd = ["codeagent-wrapper", "--backend", "codex", "-"]

    try:
        proc = subprocess.Popen(
            cmd,
            cwd=str(worktree_path),
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except FileNotFoundError:
        return 127

    state.current_process = proc
    state.last_process = proc
    try:
        # é€šè¿‡ stdin.PIPE ä¼ é€’å†…å®¹ï¼Œé¿å… heredoc æ ¼å¼é—®é¢˜
        stdout, stderr = proc.communicate(input=task_content)
    finally:
        state.current_process = None

    session_id = _parse_session_id(stdout) or _parse_session_id(stderr)
    if session_id:
        with state.lock:
            state.session_ids[issue_number] = session_id
    return proc.returncode


def _get_pr_number(issue_number: int, repo: Optional[str], cwd: Path, state: ExecState) -> Optional[int]:
    cmd = ["gh", "pr", "list", "--head", f"issue-{issue_number}"]
    if repo:
        cmd += ["--repo", repo]
    cmd += ["--json", "number", "-q", ".[0].number"]

    result = _run_capture(cmd, cwd=cwd, state=state)
    if result.returncode != 0:
        detail = (result.stderr or "").strip() or (result.stdout or "").strip()
        raise RuntimeError(detail or f"gh pr list å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰")

    raw = (result.stdout or "").strip()
    if not raw or raw == "null":
        return None
    if raw.isdigit() and int(raw) > 0:
        return int(raw)
    return None


def _build_pr_review_content(pr_number: int) -> str:
    """
    æ„å»º PR å®¡æŸ¥ä»»åŠ¡å†…å®¹ã€‚

    Args:
        pr_number: PR ç¼–å·

    Returns:
        æ ¼å¼åŒ–çš„ä»»åŠ¡å†…å®¹å­—ç¬¦ä¸²
    """
    return (
        f"å®¡æŸ¥å¹¶å¤„ç† PR #{pr_number}\n\n"
        "Requirements:\n"
        "- æ£€æŸ¥ PR ä»£ç è´¨é‡\n"
        "- è¿è¡Œç›¸å…³æµ‹è¯•\n"
        "- å¦‚æœ‰é—®é¢˜ï¼Œæä¾›ä¿®å¤å»ºè®®\n"
    )


def _run_pr_review(
    pr_number: int,
    worktree_path: Path,
    tty_stdin: Optional[TextIO],
    state: ExecState,
) -> int:
    """
    ä½¿ç”¨ codeagent-wrapper æ‰§è¡Œ PR å®¡æŸ¥ä»»åŠ¡ã€‚

    é€šè¿‡ stdin ä¼ é€’ä»»åŠ¡å†…å®¹ï¼Œé¿å… heredoc å’Œç‰¹æ®Šå­—ç¬¦é—®é¢˜ã€‚

    Args:
        pr_number: PR ç¼–å·
        worktree_path: worktree è·¯å¾„
        tty_stdin: TTY stdinï¼ˆç”¨äºäº¤äº’ï¼‰
        state: æ‰§è¡ŒçŠ¶æ€

    Returns:
        è¿›ç¨‹è¿”å›ç 
    """
    task_content = _build_pr_review_content(pr_number)

    # ä½¿ç”¨åˆ—è¡¨æ¨¡å¼æ„é€ å‘½ä»¤ï¼Œé¿å… shell è§£æ
    cmd = ["codeagent-wrapper", "--backend", "codex", "-"]

    try:
        proc = subprocess.Popen(
            cmd,
            cwd=str(worktree_path),
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except FileNotFoundError:
        return 127

    state.current_process = proc
    state.last_process = proc
    try:
        # é€šè¿‡ stdin.PIPE ä¼ é€’å†…å®¹ï¼Œé¿å… heredoc æ ¼å¼é—®é¢˜
        stdout, stderr = proc.communicate(input=task_content)
    finally:
        state.current_process = None

    return proc.returncode


def _merge_pr(pr_number: int, repo: Optional[str], cwd: Path, state: ExecState) -> tuple[bool, str]:
    cmd = ["gh", "pr", "merge", str(pr_number), "--squash", "--delete-branch", "--yes"]
    if repo:
        cmd += ["--repo", repo]

    result = _run_capture(cmd, cwd=cwd, state=state)
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    return False, detail or f"gh pr merge å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _format_duration(seconds: float) -> str:
    seconds = max(0.0, float(seconds or 0.0))
    whole = int(seconds + 0.5)  # round to nearest second
    minutes, sec = divmod(whole, 60)
    hours, minutes = divmod(minutes, 60)
    if hours > 0:
        return f"{hours}h{minutes}m{sec}s"
    if minutes > 0:
        return f"{minutes}m{sec}s"
    return f"{sec}s"


def _print_report(results: list[IssueResult], interrupted: bool) -> None:
    total = len(results)
    completed = [r for r in results if r.status == "completed"]
    failed = [r for r in results if r.status == "failed"]
    skipped = [r for r in results if r.status == "skipped"]
    interrupted_issues = [r for r in results if r.status == "interrupted"]
    total_attempts = sum(r.attempts for r in results)
    total_retries = sum(max(0, r.attempts - 1) for r in results)
    retried = [r for r in results if r.attempts > 1]
    retried_ok = [r for r in results if r.status == "completed" and r.attempts > 1]
    retried_failed = [r for r in results if r.status == "failed" and r.attempts > 1]
    total_elapsed_sec = sum(r.elapsed_sec for r in results)

    print("\nå®ŒæˆæŠ¥å‘Š:")
    if results:
        issue_col = "issue"
        title_col = "title"
        pr_col = "PR"
        status_col = "status"
        time_col = "time"
        max_title_width = 60

        table_rows: list[tuple[str, str, str, str, str]] = []
        for r in results:
            issue_val = f"#{r.number}"
            title_val = (r.title or "").strip() or "-"
            if len(title_val) > max_title_width:
                title_val = title_val[: max_title_width - 1] + "â€¦"
            pr_val = f"#{r.pr_number}" if r.pr_number else "-"
            status_val = r.status
            time_val = _format_duration(r.elapsed_sec)
            table_rows.append((issue_val, title_val, pr_val, status_val, time_val))

        w_issue = max(len(issue_col), *(len(r[0]) for r in table_rows))
        w_title = max(len(title_col), *(len(r[1]) for r in table_rows))
        w_pr = max(len(pr_col), *(len(r[2]) for r in table_rows))
        w_status = max(len(status_col), *(len(r[3]) for r in table_rows))
        w_time = max(len(time_col), *(len(r[4]) for r in table_rows))

        def _row(cols: tuple[str, str, str, str, str]) -> str:
            c1, c2, c3, c4, c5 = cols
            return (
                f"{c1:<{w_issue}}  {c2:<{w_title}}  {c3:<{w_pr}}  {c4:<{w_status}}  {c5:>{w_time}}"
            )

        print(_row((issue_col, title_col, pr_col, status_col, time_col)))
        print(_row(("-" * w_issue, "-" * w_title, "-" * w_pr, "-" * w_status, "-" * w_time)))
        for row in table_rows:
            print(_row(row))

        print(f"\n- æ€»è€—æ—¶: {_format_duration(total_elapsed_sec)}")
    print(f"- æ€»è®¡: {total}")
    print(f"- å·²å®Œæˆ: {len(completed)}")
    print(f"- å¤±è´¥: {len(failed)}")
    print(f"- æ€»å°è¯•æ¬¡æ•°: {total_attempts}")
    print(f"- æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
    print(f"- è§¦å‘é‡è¯•çš„ Issue: {len(retried)}")
    if retried_ok:
        print(f"- é‡è¯•åæˆåŠŸ: {len(retried_ok)}")
    if retried_failed:
        print(f"- é‡è¯•åä»å¤±è´¥: {len(retried_failed)}")
    if skipped:
        print(f"- å·²è·³è¿‡: {len(skipped)}")
    if interrupted or interrupted_issues:
        print("- å·²ä¸­æ–­: æ˜¯")

    if completed:
        nums = " ".join(f"#{r.number}" for r in completed)
        print(f"- å®Œæˆåˆ—è¡¨: {nums}")
    if failed:
        nums = " ".join(f"#{r.number}" for r in failed)
        print(f"- å¤±è´¥åˆ—è¡¨: {nums}")
    if interrupted_issues:
        nums = " ".join(f"#{r.number}" for r in interrupted_issues)
        print(f"- ä¸­æ–­ä½ç½®: {nums}")


def _print_cleanup_report(report: CleanupReport) -> None:
    print("\n===== Cleanup Report =====")

    total = len(report.tracked_issues)
    print(f"- è¿½è¸ª issues: {total}")
    if total == 0:
        print("- æ— éœ€æ¸…ç†")
        return

    worktree_ok = sum(1 for ok, _ in report.worktree_removed.values() if ok)
    local_ok = sum(1 for ok, _ in report.local_branch_deleted.values() if ok)
    remote_ok = sum(1 for ok, _ in report.remote_branch_deleted.values() if ok)

    print(f"- worktree æ¸…ç†: {worktree_ok}/{total}")
    if report.worktree_force_used:
        forced = sorted(report.worktree_force_used)
        if len(forced) <= 20:
            nums = " ".join(f"#{n}" for n in forced)
            print(f"- worktree --force: {len(forced)} ({nums})")
        else:
            print(f"- worktree --force: {len(forced)}")
    print(f"- æœ¬åœ°åˆ†æ”¯åˆ é™¤: {local_ok}/{total}")
    print(f"- è¿œç«¯åˆ†æ”¯åˆ é™¤: {remote_ok}/{total}")
    print(f"- git worktree prune: {'OK' if report.prune_ok else 'FAILED'}")
    if not report.prune_ok and report.prune_detail:
        print(f"  - {report.prune_detail}")

    def _print_failures(title: str, mapping: dict[int, tuple[bool, str]]) -> None:
        failed_items = [(i, d) for i, (ok, d) in mapping.items() if not ok]
        if not failed_items:
            return
        failed_items.sort(key=lambda x: x[0])
        print(f"- {title} å¤±è´¥: {len(failed_items)}")
        for issue_number, detail in failed_items[:20]:
            suffix = f": {detail}" if detail else ""
            print(f"  - #{issue_number}{suffix}")
        if len(failed_items) > 20:
            print(f"  - ... è¿˜æœ‰ {len(failed_items) - 20} ä¸ª")

    _print_failures("worktree æ¸…ç†", report.worktree_removed)
    _print_failures("æœ¬åœ°åˆ†æ”¯åˆ é™¤", report.local_branch_deleted)
    _print_failures("è¿œç«¯åˆ†æ”¯åˆ é™¤", report.remote_branch_deleted)


def _parse_issue_numbers_csv(value: str) -> list[int]:
    items = [x.strip() for x in (value or "").split(",")]
    parsed: list[int] = []
    for item in items:
        if not item:
            continue
        if not item.isdigit():
            raise ValueError(f"æ— æ•ˆ issue ç¼–å·: {item}")
        num = int(item)
        if num <= 0:
            raise ValueError(f"æ— æ•ˆ issue ç¼–å·: {item}")
        parsed.append(num)

    seen: set[int] = set()
    deduped: list[int] = []
    for num in parsed:
        if num in seen:
            continue
        seen.add(num)
        deduped.append(num)
    return deduped


def _extract_issue_numbers(text: str) -> set[int]:
    matches = ISSUE_BRANCH_PATTERN.findall(text or "")
    return {int(m) for m in matches if m.isdigit() and int(m) > 0}


def _collect_issue_numbers(repo_dir: Path, state: ExecState) -> set[int]:
    candidates: set[int] = set()
    cmds = [
        ["git", "branch", "--list", "issue-*"],
        ["git", "branch", "-r", "--list", "origin/issue-*"],
        ["git", "worktree", "list", "--porcelain"],
    ]
    for cmd in cmds:
        result = _run_capture(cmd, cwd=repo_dir, state=state)
        if result.returncode != 0:
            continue
        candidates |= _extract_issue_numbers(result.stdout or "")
    return candidates


def _get_default_base_ref(repo_dir: Path, state: ExecState) -> str:
    result = _run_capture(["git", "symbolic-ref", "refs/remotes/origin/HEAD"], cwd=repo_dir, state=state)
    if result.returncode == 0:
        ref = (result.stdout or "").strip()
        if ref:
            parts = [p for p in ref.split("/") if p]
            if len(parts) >= 2:
                return "/".join(parts[-2:])
    return "origin/main"


def _is_issue_merged_via_git(issue_number: int, repo_dir: Path, state: ExecState) -> tuple[Optional[bool], str]:
    base_ref = _get_default_base_ref(repo_dir, state)
    result = _run_capture(
        ["git", "branch", "--merged", base_ref, "--list", f"issue-{issue_number}"],
        cwd=repo_dir,
        state=state,
    )
    if result.returncode != 0:
        detail = (result.stderr or "").strip() or (result.stdout or "").strip()
        detail = detail or f"git branch --merged {base_ref} å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"
        return None, detail
    merged = bool((result.stdout or "").strip())
    if merged:
        return True, f"git: merged into {base_ref}"
    return False, ""


def _is_issue_merged_via_gh(
    issue_number: int,
    repo: Optional[str],
    repo_dir: Path,
    state: ExecState,
) -> tuple[Optional[bool], str]:
    cmd = ["gh", "pr", "list", "--state", "merged", "--head", f"issue-{issue_number}"]
    if repo:
        cmd += ["--repo", repo]
    cmd += ["--json", "number", "-q", ".[0].number"]

    result = _run_capture(cmd, cwd=repo_dir, state=state)
    if result.returncode == 0:
        raw = (result.stdout or "").strip()
        if raw and raw != "null":
            return True, ""
        return False, ""

    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    if result.returncode == 127:
        return None, detail or "gh ä¸å­˜åœ¨"
    return None, detail or f"gh pr list å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _is_issue_merged(
    issue_number: int,
    repo: Optional[str],
    repo_dir: Path,
    state: ExecState,
) -> tuple[Optional[bool], str]:
    merged, detail = _is_issue_merged_via_gh(issue_number, repo, repo_dir, state)
    if merged is not None:
        return merged, detail
    return _is_issue_merged_via_git(issue_number, repo_dir, state)


def cmd_cleanup(args, repo_dir: Path, worktree_script: Path) -> int:
    """
    æ‰‹åŠ¨æ¸…ç† issue-* ç›¸å…³èµ„æºã€‚

    - é»˜è®¤ï¼šæ¸…ç†æ‰€æœ‰å·²åˆå¹¶çš„ issue-* åˆ†æ”¯
    - --cleanup-forceï¼šæ¸…ç†æ‰€æœ‰ issue-* åˆ†æ”¯ï¼ˆä¸æ£€æŸ¥æ˜¯å¦åˆå¹¶ï¼‰
    - --cleanup-issuesï¼šä»…æ¸…ç†æŒ‡å®š issueï¼ˆé€—å·åˆ†éš”ï¼‰ï¼›ä¸ --cleanup-force åŒæ—¶ä½¿ç”¨æ—¶ä¸æ£€æŸ¥æ˜¯å¦åˆå¹¶
    """
    state = ExecState()
    started = time.monotonic()

    cleanup_force = bool(getattr(args, "cleanup_force", False))
    raw_issues = getattr(args, "cleanup_issues", None)
    specified: list[int] = []
    if raw_issues:
        try:
            specified = _parse_issue_numbers_csv(str(raw_issues))
        except ValueError as e:
            print(f"Error: --cleanup-issues è§£æå¤±è´¥: {e}", file=sys.stderr)
            return 2

    candidates = set(specified) if specified else _collect_issue_numbers(repo_dir, state)
    candidates = {n for n in candidates if n > 0}

    print("\nğŸ§¹ æ‰‹åŠ¨æ¸…ç†: --cleanup", flush=True)
    mode = "force" if cleanup_force else "merged-only"
    if specified:
        print(f"- æ¨¡å¼: {mode} (æŒ‡å®š issues)", flush=True)
    else:
        print(f"- æ¨¡å¼: {mode}", flush=True)
    print(f"- ä»“åº“ç›®å½•: {repo_dir}", flush=True)
    print(f"- å€™é€‰ issues: {len(candidates)}", flush=True)

    if not candidates:
        print("- æ— éœ€æ¸…ç†", flush=True)
        return 0

    to_clean: list[int] = []
    skipped_not_merged: list[int] = []
    skipped_unknown: dict[int, str] = {}

    for issue_number in sorted(candidates):
        if cleanup_force:
            to_clean.append(issue_number)
            continue

        merged, detail = _is_issue_merged(issue_number, getattr(args, "repo", None), repo_dir, state)
        if merged is True:
            to_clean.append(issue_number)
            continue
        if merged is False:
            skipped_not_merged.append(issue_number)
            continue
        skipped_unknown[issue_number] = detail or "æ— æ³•ç¡®è®¤æ˜¯å¦å·²åˆå¹¶"

    if skipped_not_merged:
        nums = " ".join(f"#{n}" for n in skipped_not_merged[:50])
        suffix = "" if len(skipped_not_merged) <= 50 else f" ...(+{len(skipped_not_merged) - 50})"
        print(f"- è·³è¿‡æœªåˆå¹¶: {len(skipped_not_merged)} ({nums}{suffix})", flush=True)

    if skipped_unknown:
        keys = sorted(skipped_unknown)[:20]
        nums = " ".join(f"#{n}" for n in keys)
        suffix = "" if len(skipped_unknown) <= 20 else f" ...(+{len(skipped_unknown) - 20})"
        print(f"- è·³è¿‡(çŠ¶æ€æœªçŸ¥): {len(skipped_unknown)} ({nums}{suffix})", flush=True)
        first = keys[0]
        print(f"  - ä¾‹: #{first}: {skipped_unknown[first]}", flush=True)

    print(f"- å°†æ¸…ç†: {len(to_clean)}", flush=True)
    if not to_clean:
        print("- æ— éœ€æ¸…ç†", flush=True)
        return 0

    state.created_issues = set(to_clean)
    report = _cleanup_all_resources(state=state, repo_dir=repo_dir, worktree_script=worktree_script)
    _print_cleanup_report(report)

    failures = (
        sum(1 for ok, _ in report.worktree_removed.values() if not ok)
        + sum(1 for ok, _ in report.local_branch_deleted.values() if not ok)
        + sum(1 for ok, _ in report.remote_branch_deleted.values() if not ok)
        + (0 if report.prune_ok else 1)
    )
    elapsed = time.monotonic() - started
    print(f"\n- æ¸…ç†è€—æ—¶: {_format_duration(elapsed)}", flush=True)
    if failures:
        print(f"âš ï¸ æ¸…ç†å®Œæˆï¼ˆå¤±è´¥é¡¹: {failures}ï¼‰", flush=True)
        return 1
    print("âœ… æ¸…ç†å®Œæˆ", flush=True)
    return 0


# ==================== å¹¶å‘æ‰§è¡Œæ ¸å¿ƒå‡½æ•° ====================

def _execute_single_issue(
    spec: IssueSpec,
    idx: int,
    total: int,
    prio_label: str,
    repo: Optional[str],
    repo_dir: Path,
    worktree_script: Path,
    max_retries: int,
    force_cleanup: bool,
    tty_stdin: Optional[TextIO],
    state: ExecState,
    print_lock: Lock,
) -> IssueResult:
    """
    æ‰§è¡Œå•ä¸ª issue çš„å®Œæ•´æµç¨‹ï¼ˆworktree â†’ codeagent-wrapper â†’ PR review â†’ mergeï¼‰ã€‚
    çº¿ç¨‹å®‰å…¨ï¼Œå¯ç”¨äºå¹¶å‘æ‰§è¡Œã€‚
    """
    issue_number = spec.number
    priority = spec.priority or "p2"
    title = spec.title or ""

    # èµ„æºè¿½è¸ªï¼šå³ä½¿åç»­æ­¥éª¤å¤±è´¥ä¹Ÿè¦è®°å½•
    with state.lock:
        state.created_issues.add(issue_number)

    issue_start = time.monotonic()
    observed_pr_number: Optional[int] = None
    last_error: str = ""

    # å¦‚æœæ²¡æœ‰ titleï¼Œå°è¯•è·å–
    if not title:
        title = _run_gh_issue_title(issue_number, repo, cwd=repo_dir) or ""
    title_display = title if title else "(æ— æ³•è·å–æ ‡é¢˜)"

    with print_lock:
        print(
            f"[{idx}/{total}] æ­£åœ¨å¤„ç† Issue #{issue_number}: {title_display} ({prio_label})",
            flush=True,
        )

    # æ³¨å†Œåˆ° state
    with state.lock:
        state.active_issues.add(issue_number)

    max_attempts = 1 + max_retries
    attempt_details: list[str] = []
    final_status = "failed"
    final_returncode: Optional[int] = None
    attempts = 0

    for attempt in range(1, max_attempts + 1):
        if state.interrupted:
            final_status = "interrupted"
            break

        attempts = attempt
        final_returncode = None
        worktree_path: Optional[Path] = None

        if attempt > 1:
            retry_idx = attempt - 1
            with print_lock:
                print(
                    f"ğŸ”„ Issue #{issue_number} ç¬¬ {retry_idx}/{max_retries} æ¬¡é‡è¯•...",
                    flush=True,
                )

            # æ¸…ç†ä¹‹å‰çš„ worktree
            existing_path = _get_worktree_path(worktree_script, issue_number, repo_dir, state)
            if existing_path:
                ok, detail = _remove_worktree(worktree_script, issue_number, repo_dir, state)
                if not ok:
                    ok2, detail2 = _force_remove_worktree(issue_number, existing_path, repo_dir, state)
                    if ok2:
                        ok, detail = True, ""
                    else:
                        detail = f"{detail}; {detail2}"
                if not ok:
                    with print_lock:
                        print(f"Warning: worktree æ¸…ç†å¤±è´¥: #{issue_number}: {detail}", file=sys.stderr)

            # æ¸…ç†è¿œç¨‹åˆ†æ”¯
            ok_rb, detail_rb = _cleanup_remote_branch(issue_number, repo_dir, state)
            if not ok_rb:
                with print_lock:
                    print(f"Warning: è¿œç¨‹åˆ†æ”¯æ¸…ç†å¤±è´¥: #{issue_number}: {detail_rb}", file=sys.stderr)

        try:
            worktree_path = _create_worktree(worktree_script, issue_number, repo_dir, state)
            with state.lock:
                state.active_worktrees[issue_number] = worktree_path

            rc = _run_claude(issue_number, title_display, worktree_path, state)
            if state.interrupted:
                final_status = "interrupted"
                final_returncode = rc
                break

            if rc == 0:
                pr_number = _get_pr_number(issue_number, repo, cwd=repo_dir, state=state)
                if pr_number:
                    observed_pr_number = pr_number
                    review_rc = _run_pr_review(pr_number, worktree_path, tty_stdin, state)
                    if review_rc != 0:
                        last_error = f"pr review exit={review_rc}"
                        attempt_details.append(f"attempt {attempt}: {last_error}")
                        final_returncode = review_rc
                    else:
                        ok, detail = _merge_pr(pr_number, repo, cwd=repo_dir, state=state)
                        if ok:
                            final_status = "completed"
                            final_returncode = rc
                            break
                        last_error = detail
                        attempt_details.append(f"attempt {attempt}: {detail}")
                else:
                    observed_pr_number = None
                    final_status = "completed"
                    final_returncode = rc
                    break
            else:
                last_error = f"codeagent exit={rc}"
                attempt_details.append(f"attempt {attempt}: {last_error}")
                final_returncode = rc

        except KeyboardInterrupt:
            state.interrupted = True
            final_status = "interrupted"
            break
        except Exception as e:
            last_error = str(e)
            attempt_details.append(f"attempt {attempt}: {e}")
        finally:
            if worktree_path:
                ok, detail = _remove_worktree(worktree_script, issue_number, repo_dir, state)
                if not ok and (force_cleanup or state.interrupted):
                    ok2, detail2 = _force_remove_worktree(issue_number, worktree_path, repo_dir, state)
                    if ok2:
                        ok, detail = True, ""
                    else:
                        detail = f"{detail}; {detail2}"
                if not ok:
                    with print_lock:
                        print(f"Warning: worktree æ¸…ç†å¤±è´¥: #{issue_number}: {detail}", file=sys.stderr)

            with state.lock:
                state.active_worktrees.pop(issue_number, None)

        if final_status == "completed" or state.interrupted:
            break

    elapsed_sec = time.monotonic() - issue_start
    detail = "\n".join(attempt_details).strip()
    if final_status == "failed" and not last_error:
        last_error = _last_nonempty_line(detail) or "-"

    # ä» state æ³¨é”€
    with state.lock:
        state.active_issues.discard(issue_number)

    result = IssueResult(
        number=issue_number,
        priority=priority,
        title=title,
        status=final_status,
        pr_number=observed_pr_number,
        elapsed_sec=elapsed_sec,
        attempts=attempts,
        returncode=final_returncode,
        detail=detail,
    )

    # æ‰“å°ç»“æœ
    with print_lock:
        if result.status == "completed":
            pr_text = f"ï¼ŒPR #{result.pr_number} å·²åˆå¹¶" if result.pr_number else ""
            print(
                f"âœ… Issue #{issue_number} å·²å®Œæˆ{pr_text} (è€—æ—¶ {_format_duration(result.elapsed_sec)})",
                flush=True,
            )
        elif result.status == "failed":
            print(
                f"âŒ Issue #{issue_number} å¤±è´¥ (å°è¯• {attempts}/{max_attempts}): {last_error}",
                flush=True,
            )

    return result


def _execute_batch_concurrent(
    batch_specs: list[IssueSpec],
    batch_priority: str,
    start_idx: int,
    total: int,
    repo: Optional[str],
    repo_dir: Path,
    worktree_script: Path,
    max_retries: int,
    force_cleanup: bool,
    tty_stdin: Optional[TextIO],
    state: ExecState,
    results: list[IssueResult],
    results_lock: Lock,
) -> int:
    """
    å¹¶å‘æ‰§è¡Œä¸€ä¸ªæ‰¹æ¬¡å†…çš„æ‰€æœ‰ issuesï¼ˆDAG è°ƒåº¦ï¼Œä¾èµ–æ„ŸçŸ¥ï¼‰ã€‚
    è¿”å›å®Œæˆçš„ issue æ•°é‡ã€‚
    """
    if not batch_specs:
        return 0

    prio_label = batch_priority.strip().upper() if batch_priority else "P2"

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–
    has_dependencies = any(spec.dependencies for spec in batch_specs)

    # è®¡ç®—è‡ªé€‚åº”å¹¶å‘æ•°
    max_workers = _calculate_max_workers(batch_priority, len(batch_specs), has_dependencies)

    print(f"ğŸ“¦ {prio_label} æ‰¹æ¬¡ ({len(batch_specs)} issues, å¹¶å‘={max_workers})", flush=True)

    # åˆ›å»º DAG è°ƒåº¦å™¨
    scheduler = DagScheduler(batch_specs)
    print_lock = Lock()
    batch_completed = 0
    current_idx = start_idx

    # åˆ›å»º issue number -> spec æ˜ å°„
    spec_map = {s.number: s for s in batch_specs}
    # åˆ›å»º issue number -> idx æ˜ å°„
    idx_map = {}
    for i, spec in enumerate(batch_specs):
        idx_map[spec.number] = start_idx + i

    def execute_issue(issue_num: int) -> IssueResult:
        """æ‰§è¡Œå•ä¸ª issue çš„åŒ…è£…å‡½æ•°"""
        spec = spec_map[issue_num]
        idx = idx_map[issue_num]
        return _execute_single_issue(
            spec=spec,
            idx=idx,
            total=total,
            prio_label=prio_label,
            repo=repo,
            repo_dir=repo_dir,
            worktree_script=worktree_script,
            max_retries=max_retries,
            force_cleanup=force_cleanup,
            tty_stdin=tty_stdin,
            state=state,
            print_lock=print_lock,
        )

    # ä½¿ç”¨ ThreadPoolExecutor å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures: dict[int, Any] = {}  # issue_number -> Future

        while not scheduler.is_done() and not state.interrupted:
            # è·å–å¯ä»¥å¼€å§‹çš„ issues
            ready_issues = scheduler.get_ready_issues()

            # æäº¤æ–°ä»»åŠ¡
            for issue_num in ready_issues:
                if issue_num not in futures and scheduler.mark_started(issue_num):
                    future = executor.submit(execute_issue, issue_num)
                    futures[issue_num] = future

            # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
            completed_futures = []
            for issue_num, future in list(futures.items()):
                if future.done():
                    completed_futures.append((issue_num, future))

            for issue_num, future in completed_futures:
                try:
                    result = future.result()
                    with results_lock:
                        results.append(result)

                    if result.status == "completed":
                        scheduler.mark_completed(issue_num)
                        batch_completed += 1
                    else:
                        scheduler.mark_failed(issue_num)
                except Exception as e:
                    # å¼‚å¸¸æƒ…å†µï¼Œæ ‡è®°ä¸ºå¤±è´¥
                    scheduler.mark_failed(issue_num)
                    with print_lock:
                        print(f"âŒ Issue #{issue_num} æ‰§è¡Œå¼‚å¸¸: {e}", file=sys.stderr)

                del futures[issue_num]

            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«é˜»å¡çš„ issues
            blocked = scheduler.has_blocked_issues()
            if blocked and not futures and not ready_issues:
                # æ‰€æœ‰å¯æ‰§è¡Œçš„éƒ½å®Œæˆäº†ï¼Œä½†è¿˜æœ‰è¢«é˜»å¡çš„
                with print_lock:
                    blocked_nums = " ".join(f"#{n}" for n in blocked)
                    print(f"âš ï¸ ä»¥ä¸‹ issues å› ä¾èµ–å¤±è´¥è€Œè·³è¿‡: {blocked_nums}", flush=True)

                # æ ‡è®°è¢«é˜»å¡çš„ issues ä¸º skipped
                for issue_num in blocked:
                    scheduler.mark_failed(issue_num)
                    spec = spec_map[issue_num]
                    with results_lock:
                        results.append(IssueResult(
                            number=issue_num,
                            priority=spec.priority,
                            title=spec.title,
                            status="skipped",
                            detail="ä¾èµ–çš„ issue å¤±è´¥",
                        ))
                break

            # çŸ­æš‚ä¼‘çœ é¿å… CPU å ç”¨è¿‡é«˜
            if futures:
                time.sleep(0.1)

        # ç­‰å¾…æ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡å®Œæˆï¼ˆä¸­æ–­æ—¶ä¹Ÿè¦ç­‰å¾…ï¼‰
        for issue_num, future in futures.items():
            try:
                result = future.result(timeout=1.0)
                with results_lock:
                    results.append(result)
                if result.status == "completed":
                    batch_completed += 1
            except Exception:
                pass

    if not state.interrupted:
        print(f"ğŸ“¦ {prio_label} æ‰¹æ¬¡å®Œæˆ ({batch_completed}/{len(batch_specs)})", flush=True)

    return batch_completed


def main() -> None:
    parser = argparse.ArgumentParser(description="æŒ‰ priority æ‰¹æ¬¡å¹¶å‘æ‰§è¡Œ Issuesï¼ˆworktree + codeagent-wrapperï¼‰")
    parser.add_argument("--input", help="priority_batcher.py --json çš„è¾“å‡ºæ–‡ä»¶ï¼ˆé»˜è®¤ä» stdin è¯»å–ï¼‰")
    parser.add_argument("--repo", help="ç”¨äº gh issue view çš„ä»“åº“ï¼ˆé»˜è®¤ä½¿ç”¨å½“å‰ä»“åº“ï¼‰")
    parser.add_argument("--repo-dir", default=".", help="æ‰§è¡Œ git/gh/worktree çš„ä»“åº“ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰")
    parser.add_argument(
        "--worktree-script",
        default=str(DEFAULT_WORKTREE_SCRIPT),
        help="worktree.py è„šæœ¬è·¯å¾„",
    )
    parser.add_argument(
        "--force-cleanup",
        action="store_true",
        help="æ¸…ç† worktree å¤±è´¥æ—¶ï¼Œå°è¯•ä½¿ç”¨ git worktree remove --force",
    )
    parser.add_argument(
        "--cleanup",
        action="store_true",
        help="æ‰‹åŠ¨æ¸…ç† issue-* ç›¸å…³èµ„æºï¼ˆé»˜è®¤ä»…æ¸…ç†å·²åˆå¹¶åˆ†æ”¯ï¼‰",
    )
    parser.add_argument(
        "--cleanup-force",
        action="store_true",
        help="ä¸ --cleanup ä¸€èµ·ä½¿ç”¨ï¼šæ¸…ç†æ‰€æœ‰ issue-* åˆ†æ”¯ï¼ˆä¸æ£€æŸ¥æ˜¯å¦åˆå¹¶ï¼‰",
    )
    parser.add_argument(
        "--cleanup-issues",
        help="ä¸ --cleanup ä¸€èµ·ä½¿ç”¨ï¼šä»…æ¸…ç†æŒ‡å®š issue ç¼–å·åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ 123,124ï¼‰",
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=3,
        help="æ¯ä¸ª issue å¤±è´¥åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰",
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=0,
        help="è¦†ç›–è‡ªé€‚åº”å¹¶å‘æ•°ï¼Œ0 è¡¨ç¤ºä½¿ç”¨è‡ªé€‚åº”è®¡ç®—ï¼ˆé»˜è®¤ 0ï¼‰",
    )
    args = parser.parse_args()

    repo_dir = Path(args.repo_dir).expanduser().resolve()
    worktree_script = Path(args.worktree_script).expanduser().resolve()

    if not worktree_script.exists():
        print(f"Error: worktree.py ä¸å­˜åœ¨: {worktree_script}", file=sys.stderr)
        sys.exit(1)

    if args.cleanup:
        sys.exit(cmd_cleanup(args=args, repo_dir=repo_dir, worktree_script=worktree_script))

    if args.max_retries < 0:
        print("Error: --max-retries å¿…é¡» >= 0", file=sys.stderr)
        sys.exit(2)

    state = ExecState()
    results: list[IssueResult] = []
    results_lock = Lock()
    tty_stdin = _open_tty_stdin()

    def _handle_sigint(_signum, _frame):
        state.interrupted = True
        # å‘æ‰€æœ‰æ´»è·ƒè¿›ç¨‹å‘é€ SIGINT
        with state.lock:
            for proc in state.active_processes.values():
                if proc and proc.poll() is None:
                    try:
                        proc.send_signal(signal.SIGINT)
                    except Exception:
                        pass
        raise KeyboardInterrupt

    signal.signal(signal.SIGINT, _handle_sigint)

    data = _read_json_input(args.input)
    upstream_warnings = data.get("warnings")
    if isinstance(upstream_warnings, list):
        for w in upstream_warnings:
            if isinstance(w, str) and w.strip():
                print(f"Warning: {w.strip()}", file=sys.stderr)
    specs, warnings = _extract_specs(data)
    if warnings:
        for w in warnings:
            print(f"Warning: {w}", file=sys.stderr)

    total = len(specs)
    if total == 0:
        _print_report([], interrupted=False)
        return

    print(f"ğŸš€ å¼€å§‹å¤„ç† (å…± {total} ä¸ª issues)", flush=True)

    # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
    batches: list[tuple[str, list[IssueSpec]]] = []
    for spec in specs:
        priority = spec.priority or "p2"
        if not batches or batches[-1][0] != priority:
            batches.append((priority, [spec]))
        else:
            batches[-1][1].append(spec)

    try:
        idx = 1
        for batch_priority, batch_specs in batches:
            if state.interrupted:
                break

            # å¹¶å‘æ‰§è¡Œæ‰¹æ¬¡
            _execute_batch_concurrent(
                batch_specs=batch_specs,
                batch_priority=batch_priority,
                start_idx=idx,
                total=total,
                repo=args.repo,
                repo_dir=repo_dir,
                worktree_script=worktree_script,
                max_retries=args.max_retries,
                force_cleanup=args.force_cleanup,
                tty_stdin=tty_stdin,
                state=state,
                results=results,
                results_lock=results_lock,
            )

            idx += len(batch_specs)

    except KeyboardInterrupt:
        state.interrupted = True
        # æ¸…ç†æ‰€æœ‰æ´»è·ƒçš„ worktrees
        with state.lock:
            for issue_num, worktree_path in list(state.active_worktrees.items()):
                _force_remove_worktree(issue_num, worktree_path, repo_dir, state)

    finally:
        cleanup_report: Optional[CleanupReport] = None
        try:
            cleanup_report = _cleanup_all_resources(state=state, repo_dir=repo_dir, worktree_script=worktree_script)
        except Exception as e:
            print(f"Warning: èµ„æºæ¸…ç†å¼‚å¸¸: {e}", file=sys.stderr)

        if tty_stdin:
            try:
                tty_stdin.close()
            except Exception:
                pass
        _print_report(results, interrupted=state.interrupted)
        if cleanup_report is not None:
            _print_cleanup_report(cleanup_report)

    if state.interrupted:
        sys.exit(130)
    if any(r.status == "failed" for r in results):
        sys.exit(1)


if __name__ == "__main__":
    main()
