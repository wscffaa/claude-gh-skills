#!/usr/bin/env python3
"""
æ ¹æ® priority_batcher.py --json çš„è¾“å‡ºï¼ŒæŒ‰æ‰¹æ¬¡å¹¶å‘æ‰§è¡Œ issueã€‚

åŠŸèƒ½:
- ä» stdin æˆ– --input æ–‡ä»¶è¯»å– JSONï¼ˆpriority_batcher.py --json è¾“å‡ºï¼‰
- æ¯æ‰¹æ¬¡å†…æ”¯æŒå¹¶å‘æ‰§è¡Œï¼ˆDAG è°ƒåº¦ï¼Œä¾èµ–æ„ŸçŸ¥ï¼‰
- è‡ªé€‚åº”å¹¶å‘æ•°ï¼šæ ¹æ®ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»åŠ¨æ€è°ƒæ•´
  - P0: max_workers=4ï¼ˆç´§æ€¥ï¼Œé«˜å¹¶å‘ï¼‰
  - P1: max_workers=3
  - P2: max_workers=2
  - P3: max_workers=1
  - æœ‰ä¾èµ–æ—¶å¹¶å‘æ•° -1
- å¤ç”¨ worktree.py è„šæœ¬è¿›è¡Œ worktree ç®¡ç†ï¼ˆåŒç›®å½•ä¸‹çš„ worktree.pyï¼‰
- æ¯ä¸ª issue åˆ›å»ºç‹¬ç«‹ worktree: {repo}-worktrees/issue-{number}
- ä½¿ç”¨ subprocess å¯åŠ¨ç‹¬ç«‹ Claude ä¼šè¯: claude -p "/gh-issue-implement {number}"
- å¤±è´¥æ”¯æŒé‡è¯•ï¼šæ¸…ç† worktree ä¸è¿œç¨‹åˆ†æ”¯åé‡è¯•ï¼ˆ--max-retriesï¼‰
- è‹¥æ£€æµ‹åˆ°å¯¹åº” PRï¼ˆhead=issue-{number}ï¼‰ï¼Œè‡ªåŠ¨æ‰§è¡Œ PR Reviewï¼ˆclaude -p "/gh-pr-review {pr_number}"ï¼‰å¹¶åˆå¹¶ï¼ˆgh pr merge --squash --delete-branchï¼‰
- issue å®Œæˆåè‡ªåŠ¨æ¸…ç† worktree
- Ctrl+Cï¼ˆSIGINTï¼‰æ—¶æ¸…ç†å½“å‰ worktree å¹¶è¾“å‡ºå·²å®ŒæˆæŠ¥å‘Š

è¾“å‡ºæ ¼å¼:
- å¼€å§‹å¤„ç†: ğŸš€ å¼€å§‹å¤„ç† (å…± {total} ä¸ª issues)
- æ¯ä¸ªæ‰¹æ¬¡å¼€å§‹: ğŸ“¦ {PRIORITY} æ‰¹æ¬¡ ({count} issues, å¹¶å‘={workers})
- æ¯ä¸ª issue å¼€å§‹: [2/10] æ­£åœ¨å¤„ç† Issue #42: xxx (P1)
- æ¯ä¸ª issue å®Œæˆ: âœ… Issue #42 å·²å®Œæˆï¼ŒPR #123 å·²åˆå¹¶ (è€—æ—¶ 2m30s)
- æ¯ä¸ª issue å¤±è´¥: âŒ Issue #42 å¤±è´¥ (å°è¯• 2/4): xxx
- æ¯ä¸ªæ‰¹æ¬¡å®Œæˆ: ğŸ“¦ {PRIORITY} æ‰¹æ¬¡å®Œæˆ ({completed}/{total})
- æœ€ç»ˆè¾“å‡ºå®ŒæˆæŠ¥å‘Š
"""

from __future__ import annotations

import argparse
import asyncio
import json
import signal
import subprocess
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from pathlib import Path
from threading import Lock
from typing import Any, Optional, TextIO


DEFAULT_WORKTREE_SCRIPT = Path(__file__).parent / "worktree.py"


@dataclass
class IssueSpec:
    number: int
    priority: str
    title: str = ""
    dependencies: list[int] = field(default_factory=list)


@dataclass
class IssueResult:
    number: int
    priority: str
    title: str
    status: str  # completed | failed | interrupted | skipped
    pr_number: Optional[int] = None  # PR ç¼–å·
    elapsed_sec: float = 0.0  # è€—æ—¶ï¼ˆç§’ï¼‰
    attempts: int = 1
    returncode: Optional[int] = None
    detail: str = ""


@dataclass
class ExecState:
    interrupted: bool = False
    current_issue: Optional[int] = None
    current_worktree_path: Optional[Path] = None
    current_process: Optional[subprocess.Popen] = None
    last_process: Optional[subprocess.Popen] = None
    # å¹¶å‘æ‰§è¡Œç›¸å…³
    active_issues: set[int] = field(default_factory=set)
    active_processes: dict[int, subprocess.Popen] = field(default_factory=dict)
    active_worktrees: dict[int, Path] = field(default_factory=dict)
    lock: Lock = field(default_factory=Lock)


# ==================== è‡ªé€‚åº”å¹¶å‘æ•°è®¡ç®— ====================

def _calculate_max_workers(priority: str, batch_size: int, has_dependencies: bool) -> int:
    """
    æ ¹æ®ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»è®¡ç®—æœ€å¤§å¹¶å‘æ•°ã€‚

    è§„åˆ™ï¼š
    - P0: åŸºç¡€å¹¶å‘æ•° 4ï¼ˆç´§æ€¥ä»»åŠ¡ï¼Œå°½å¿«å®Œæˆï¼‰
    - P1: åŸºç¡€å¹¶å‘æ•° 3
    - P2: åŸºç¡€å¹¶å‘æ•° 2
    - P3: åŸºç¡€å¹¶å‘æ•° 1ï¼ˆä½ä¼˜å…ˆçº§ï¼ŒèŠ‚çœèµ„æºï¼‰
    - æœ‰ä¾èµ–æ—¶ï¼šå¹¶å‘æ•° -1ï¼ˆé¿å…è¿‡å¤šç­‰å¾…ï¼‰
    - æœ€ç»ˆå– min(base, batch_size)
    """
    base = {
        "p0": 4,
        "p1": 3,
        "p2": 2,
        "p3": 1,
    }.get(priority.lower(), 2)

    if has_dependencies:
        base = max(1, base - 1)

    return max(1, min(base, batch_size))


# ==================== DAG è°ƒåº¦å™¨ ====================

class DagScheduler:
    """
    ä¾èµ–æ„ŸçŸ¥çš„ DAG è°ƒåº¦å™¨ã€‚

    - ç»´æŠ¤ pending/in_progress/completed ä¸‰ä¸ªçŠ¶æ€é›†åˆ
    - get_ready_issues() è¿”å›æ‰€æœ‰ä¾èµ–å·²å®Œæˆçš„å¾…å¤„ç† issue
    - æ”¯æŒå¹¶å‘è°ƒç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    """

    def __init__(self, specs: list[IssueSpec]):
        self.specs = {s.number: s for s in specs}
        self.completed: set[int] = set()
        self.failed: set[int] = set()
        self.in_progress: set[int] = set()
        self.pending: set[int] = set(s.number for s in specs)
        self._lock = Lock()

    def get_ready_issues(self) -> list[int]:
        """è¿”å›æ‰€æœ‰ä¾èµ–å·²å®Œæˆä¸”æœªå¼€å§‹çš„ issue ç¼–å·"""
        with self._lock:
            ready = []
            for num in list(self.pending):
                spec = self.specs[num]
                # ä¾èµ–å¿…é¡»å…¨éƒ¨å®Œæˆï¼ˆä¸å«å¤±è´¥ï¼‰
                deps_met = all(
                    dep in self.completed
                    for dep in spec.dependencies
                    if dep in self.specs
                )
                if deps_met:
                    ready.append(num)
            return ready

    def mark_started(self, num: int) -> bool:
        """æ ‡è®° issue ä¸ºè¿›è¡Œä¸­ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        with self._lock:
            if num not in self.pending:
                return False
            self.pending.discard(num)
            self.in_progress.add(num)
            return True

    def mark_completed(self, num: int):
        """æ ‡è®° issue ä¸ºå·²å®Œæˆ"""
        with self._lock:
            self.in_progress.discard(num)
            self.completed.add(num)

    def mark_failed(self, num: int):
        """æ ‡è®° issue ä¸ºå¤±è´¥"""
        with self._lock:
            self.in_progress.discard(num)
            self.failed.add(num)

    def is_done(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ issue éƒ½å·²å¤„ç†"""
        with self._lock:
            return len(self.pending) == 0 and len(self.in_progress) == 0

    def has_blocked_issues(self) -> list[int]:
        """è¿”å›å› ä¾èµ–å¤±è´¥è€Œè¢«é˜»å¡çš„ issue"""
        with self._lock:
            blocked = []
            for num in list(self.pending):
                spec = self.specs[num]
                # å¦‚æœä»»ä¸€ä¾èµ–å¤±è´¥ï¼Œåˆ™è¯¥ issue è¢«é˜»å¡
                if any(dep in self.failed for dep in spec.dependencies if dep in self.specs):
                    blocked.append(num)
            return blocked


def _read_json_input(path: Optional[str]) -> dict[str, Any]:
    if path and path != "-":
        try:
            raw = Path(path).read_text(encoding="utf-8")
        except OSError as e:
            print(f"Error: è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        if sys.stdin.isatty():
            print("Error: æœªæä¾›è¾“å…¥ï¼Œè¯·é€šè¿‡ stdin ç®¡é“æˆ– --input æŒ‡å®š JSON æ–‡ä»¶", file=sys.stderr)
            sys.exit(1)
        raw = sys.stdin.read()

    try:
        data = json.loads(raw)
    except json.JSONDecodeError as e:
        print(f"Error: JSON è§£æå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    if not isinstance(data, dict):
        print("Error: è¾“å…¥ JSON é¡¶å±‚å¿…é¡»ä¸ºå¯¹è±¡ï¼ˆåŒ…å« batches å­—æ®µï¼‰", file=sys.stderr)
        sys.exit(1)
    return data


def _extract_specs(data: dict[str, Any]) -> tuple[list[IssueSpec], list[str]]:
    """
    ä» priority_batcher.py --json è¾“å‡ºä¸­æå– IssueSpec åˆ—è¡¨ã€‚

    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. æ–°æ ¼å¼ï¼ˆæ¨èï¼‰ï¼šissues ä¸ºå¯¹è±¡æ•°ç»„
       {"number": 42, "title": "xxx", "dependencies": [41]}
    2. æ—§æ ¼å¼ï¼ˆå…¼å®¹ï¼‰ï¼šissues ä¸ºæ•´æ•°æ•°ç»„
       [42, 43, 44]
    """
    batches = data.get("batches")
    if not isinstance(batches, list):
        print("Error: è¾“å…¥ JSON ç¼ºå°‘ batches åˆ—è¡¨ï¼ˆpriority_batcher.py --json è¾“å‡ºï¼‰", file=sys.stderr)
        sys.exit(1)

    warnings: list[str] = []
    specs: list[IssueSpec] = []
    seen: set[int] = set()

    for batch in batches:
        if not isinstance(batch, dict):
            continue
        priority = str(batch.get("priority", "")).strip().lower()
        raw_issues = batch.get("issues")
        if not isinstance(raw_issues, list):
            continue
        for raw in raw_issues:
            number: Optional[int] = None
            title: str = ""
            dependencies: list[int] = []

            # æ–°æ ¼å¼ï¼šå¯¹è±¡
            if isinstance(raw, dict):
                number = raw.get("number")
                if not isinstance(number, int):
                    continue
                title = str(raw.get("title", ""))
                raw_deps = raw.get("dependencies", [])
                if isinstance(raw_deps, list):
                    dependencies = [d for d in raw_deps if isinstance(d, int)]
            # æ—§æ ¼å¼ï¼šæ•´æ•°
            elif isinstance(raw, int):
                number = raw
            elif isinstance(raw, str) and raw.strip().isdigit():
                number = int(raw.strip())

            if not number or number <= 0:
                continue
            if number in seen:
                warnings.append(f"é‡å¤ issue: #{number} å·²è·³è¿‡é‡å¤æ¡ç›®")
                continue
            seen.add(number)
            specs.append(IssueSpec(
                number=number,
                priority=priority or "p2",
                title=title,
                dependencies=dependencies,
            ))

    return specs, warnings


def _open_tty_stdin() -> Optional[TextIO]:
    if sys.stdin.isatty():
        return None
    try:
        return open("/dev/tty", "r")
    except OSError:
        return None


def _run_gh_issue_title(issue_number: int, repo: Optional[str], cwd: Path) -> str:
    cmd = ["gh", "issue", "view", str(issue_number)]
    if repo:
        cmd += ["--repo", repo]
    cmd += ["--json", "title", "-q", ".title"]

    for attempt in range(2):
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=20, cwd=str(cwd))
        except subprocess.TimeoutExpired:
            if attempt == 0:
                continue
            return ""
        except FileNotFoundError:
            return ""
        except Exception:
            return ""

        if result.returncode == 0:
            return (result.stdout or "").strip()
        if attempt == 0:
            continue
        return ""

    return ""


def _last_nonempty_line(text: str) -> str:
    lines = [ln.strip() for ln in (text or "").splitlines() if ln.strip()]
    return lines[-1] if lines else ""


def _stop_process(proc: subprocess.Popen, timeout_sec: float = 5.0) -> None:
    if proc.poll() is not None:
        return
    try:
        proc.send_signal(signal.SIGINT)
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
        return
    except subprocess.TimeoutExpired:
        pass

    try:
        proc.terminate()
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
        return
    except subprocess.TimeoutExpired:
        pass

    try:
        proc.kill()
    except Exception:
        pass
    try:
        proc.wait(timeout=timeout_sec)
    except Exception:
        pass


def _run_capture(cmd: list[str], cwd: Path, state: ExecState) -> subprocess.CompletedProcess[str]:
    try:
        proc = subprocess.Popen(cmd, cwd=str(cwd), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    except FileNotFoundError as e:
        return subprocess.CompletedProcess(cmd, 127, "", str(e))

    state.current_process = proc
    state.last_process = proc
    try:
        stdout, stderr = proc.communicate()
    finally:
        state.current_process = None

    return subprocess.CompletedProcess(cmd, proc.returncode, stdout, stderr)


def _create_worktree(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> Path:
    result = _run_capture(["python3", str(script_path), "create", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode != 0:
        detail = (result.stderr or "").strip() or (result.stdout or "").strip()
        raise RuntimeError(detail or f"worktree create å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰")

    path_str = _last_nonempty_line(result.stdout)
    if not path_str:
        probe = _run_capture(["python3", str(script_path), "path", str(issue_number)], cwd=repo_dir, state=state)
        if probe.returncode == 0:
            path_str = (probe.stdout or "").strip()

    if not path_str:
        raise RuntimeError("æ— æ³•è§£æ worktree è·¯å¾„")
    return Path(path_str)


def _remove_worktree(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    result = _run_capture(["python3", str(script_path), "remove", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    return False, detail or f"worktree remove å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _get_worktree_path(script_path: Path, issue_number: int, repo_dir: Path, state: ExecState) -> Optional[Path]:
    result = _run_capture(["python3", str(script_path), "path", str(issue_number)], cwd=repo_dir, state=state)
    if result.returncode != 0:
        return None
    path_str = (result.stdout or "").strip()
    return Path(path_str) if path_str else None


def _force_remove_worktree(issue_number: int, worktree_path: Path, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    result = _run_capture(
        ["git", "worktree", "remove", "--force", str(worktree_path)],
        cwd=repo_dir,
        state=state,
    )
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    detail = detail or f"git worktree remove --force å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"
    return False, detail


def _cleanup_remote_branch(issue_number: int, repo_dir: Path, state: ExecState) -> tuple[bool, str]:
    branch = f"issue-{issue_number}"
    result = _run_capture(["git", "push", "origin", "--delete", branch], cwd=repo_dir, state=state)
    if result.returncode == 0:
        return True, ""

    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    detail_lower = detail.lower()
    if "remote ref does not exist" in detail_lower:
        return True, ""

    return False, detail or f"git push origin --delete {branch} å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _run_claude(issue_number: int, worktree_path: Path, tty_stdin: Optional[TextIO], state: ExecState) -> int:
    cmd = ["claude", "-p", f"/gh-issue-implement {issue_number}"]
    try:
        proc = subprocess.Popen(cmd, cwd=str(worktree_path), stdin=tty_stdin)
    except FileNotFoundError:
        return 127

    state.current_process = proc
    state.last_process = proc
    try:
        while True:
            try:
                return proc.wait(timeout=0.2)
            except subprocess.TimeoutExpired:
                continue
    finally:
        state.current_process = None


def _get_pr_number(issue_number: int, repo: Optional[str], cwd: Path, state: ExecState) -> Optional[int]:
    cmd = ["gh", "pr", "list", "--head", f"issue-{issue_number}"]
    if repo:
        cmd += ["--repo", repo]
    cmd += ["--json", "number", "-q", ".[0].number"]

    result = _run_capture(cmd, cwd=cwd, state=state)
    if result.returncode != 0:
        detail = (result.stderr or "").strip() or (result.stdout or "").strip()
        raise RuntimeError(detail or f"gh pr list å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰")

    raw = (result.stdout or "").strip()
    if not raw or raw == "null":
        return None
    if raw.isdigit() and int(raw) > 0:
        return int(raw)
    return None


def _run_pr_review(
    pr_number: int,
    worktree_path: Path,
    tty_stdin: Optional[TextIO],
    state: ExecState,
) -> int:
    cmd = ["claude", "-p", f"/gh-pr-review {pr_number}"]
    try:
        proc = subprocess.Popen(cmd, cwd=str(worktree_path), stdin=tty_stdin)
    except FileNotFoundError:
        return 127

    state.current_process = proc
    state.last_process = proc
    try:
        while True:
            try:
                return proc.wait(timeout=0.2)
            except subprocess.TimeoutExpired:
                continue
    finally:
        state.current_process = None


def _merge_pr(pr_number: int, repo: Optional[str], cwd: Path, state: ExecState) -> tuple[bool, str]:
    cmd = ["gh", "pr", "merge", str(pr_number), "--squash", "--delete-branch", "--yes"]
    if repo:
        cmd += ["--repo", repo]

    result = _run_capture(cmd, cwd=cwd, state=state)
    if result.returncode == 0:
        return True, ""
    detail = (result.stderr or "").strip() or (result.stdout or "").strip()
    return False, detail or f"gh pr merge å¤±è´¥ï¼ˆexit={result.returncode}ï¼‰"


def _format_duration(seconds: float) -> str:
    seconds = max(0.0, float(seconds or 0.0))
    whole = int(seconds + 0.5)  # round to nearest second
    minutes, sec = divmod(whole, 60)
    hours, minutes = divmod(minutes, 60)
    if hours > 0:
        return f"{hours}h{minutes}m{sec}s"
    if minutes > 0:
        return f"{minutes}m{sec}s"
    return f"{sec}s"


def _print_report(results: list[IssueResult], interrupted: bool) -> None:
    total = len(results)
    completed = [r for r in results if r.status == "completed"]
    failed = [r for r in results if r.status == "failed"]
    skipped = [r for r in results if r.status == "skipped"]
    interrupted_issues = [r for r in results if r.status == "interrupted"]
    total_attempts = sum(r.attempts for r in results)
    total_retries = sum(max(0, r.attempts - 1) for r in results)
    retried = [r for r in results if r.attempts > 1]
    retried_ok = [r for r in results if r.status == "completed" and r.attempts > 1]
    retried_failed = [r for r in results if r.status == "failed" and r.attempts > 1]
    total_elapsed_sec = sum(r.elapsed_sec for r in results)

    print("\nå®ŒæˆæŠ¥å‘Š:")
    if results:
        issue_col = "issue"
        title_col = "title"
        pr_col = "PR"
        status_col = "status"
        time_col = "time"
        max_title_width = 60

        table_rows: list[tuple[str, str, str, str, str]] = []
        for r in results:
            issue_val = f"#{r.number}"
            title_val = (r.title or "").strip() or "-"
            if len(title_val) > max_title_width:
                title_val = title_val[: max_title_width - 1] + "â€¦"
            pr_val = f"#{r.pr_number}" if r.pr_number else "-"
            status_val = r.status
            time_val = _format_duration(r.elapsed_sec)
            table_rows.append((issue_val, title_val, pr_val, status_val, time_val))

        w_issue = max(len(issue_col), *(len(r[0]) for r in table_rows))
        w_title = max(len(title_col), *(len(r[1]) for r in table_rows))
        w_pr = max(len(pr_col), *(len(r[2]) for r in table_rows))
        w_status = max(len(status_col), *(len(r[3]) for r in table_rows))
        w_time = max(len(time_col), *(len(r[4]) for r in table_rows))

        def _row(cols: tuple[str, str, str, str, str]) -> str:
            c1, c2, c3, c4, c5 = cols
            return (
                f"{c1:<{w_issue}}  {c2:<{w_title}}  {c3:<{w_pr}}  {c4:<{w_status}}  {c5:>{w_time}}"
            )

        print(_row((issue_col, title_col, pr_col, status_col, time_col)))
        print(_row(("-" * w_issue, "-" * w_title, "-" * w_pr, "-" * w_status, "-" * w_time)))
        for row in table_rows:
            print(_row(row))

        print(f"\n- æ€»è€—æ—¶: {_format_duration(total_elapsed_sec)}")
    print(f"- æ€»è®¡: {total}")
    print(f"- å·²å®Œæˆ: {len(completed)}")
    print(f"- å¤±è´¥: {len(failed)}")
    print(f"- æ€»å°è¯•æ¬¡æ•°: {total_attempts}")
    print(f"- æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
    print(f"- è§¦å‘é‡è¯•çš„ Issue: {len(retried)}")
    if retried_ok:
        print(f"- é‡è¯•åæˆåŠŸ: {len(retried_ok)}")
    if retried_failed:
        print(f"- é‡è¯•åä»å¤±è´¥: {len(retried_failed)}")
    if skipped:
        print(f"- å·²è·³è¿‡: {len(skipped)}")
    if interrupted or interrupted_issues:
        print("- å·²ä¸­æ–­: æ˜¯")

    if completed:
        nums = " ".join(f"#{r.number}" for r in completed)
        print(f"- å®Œæˆåˆ—è¡¨: {nums}")
    if failed:
        nums = " ".join(f"#{r.number}" for r in failed)
        print(f"- å¤±è´¥åˆ—è¡¨: {nums}")
    if interrupted_issues:
        nums = " ".join(f"#{r.number}" for r in interrupted_issues)
        print(f"- ä¸­æ–­ä½ç½®: {nums}")


# ==================== å¹¶å‘æ‰§è¡Œæ ¸å¿ƒå‡½æ•° ====================

def _execute_single_issue(
    spec: IssueSpec,
    idx: int,
    total: int,
    prio_label: str,
    repo: Optional[str],
    repo_dir: Path,
    worktree_script: Path,
    max_retries: int,
    force_cleanup: bool,
    tty_stdin: Optional[TextIO],
    state: ExecState,
    print_lock: Lock,
) -> IssueResult:
    """
    æ‰§è¡Œå•ä¸ª issue çš„å®Œæ•´æµç¨‹ï¼ˆworktree â†’ claude â†’ PR review â†’ mergeï¼‰ã€‚
    çº¿ç¨‹å®‰å…¨ï¼Œå¯ç”¨äºå¹¶å‘æ‰§è¡Œã€‚
    """
    issue_number = spec.number
    priority = spec.priority or "p2"
    title = spec.title or ""

    issue_start = time.monotonic()
    observed_pr_number: Optional[int] = None
    last_error: str = ""

    # å¦‚æœæ²¡æœ‰ titleï¼Œå°è¯•è·å–
    if not title:
        title = _run_gh_issue_title(issue_number, repo, cwd=repo_dir) or ""
    title_display = title if title else "(æ— æ³•è·å–æ ‡é¢˜)"

    with print_lock:
        print(
            f"[{idx}/{total}] æ­£åœ¨å¤„ç† Issue #{issue_number}: {title_display} ({prio_label})",
            flush=True,
        )

    # æ³¨å†Œåˆ° state
    with state.lock:
        state.active_issues.add(issue_number)

    max_attempts = 1 + max_retries
    attempt_details: list[str] = []
    final_status = "failed"
    final_returncode: Optional[int] = None
    attempts = 0

    for attempt in range(1, max_attempts + 1):
        if state.interrupted:
            final_status = "interrupted"
            break

        attempts = attempt
        final_returncode = None
        worktree_path: Optional[Path] = None

        if attempt > 1:
            retry_idx = attempt - 1
            with print_lock:
                print(
                    f"ğŸ”„ Issue #{issue_number} ç¬¬ {retry_idx}/{max_retries} æ¬¡é‡è¯•...",
                    flush=True,
                )

            # æ¸…ç†ä¹‹å‰çš„ worktree
            existing_path = _get_worktree_path(worktree_script, issue_number, repo_dir, state)
            if existing_path:
                ok, detail = _remove_worktree(worktree_script, issue_number, repo_dir, state)
                if not ok:
                    ok2, detail2 = _force_remove_worktree(issue_number, existing_path, repo_dir, state)
                    if ok2:
                        ok, detail = True, ""
                    else:
                        detail = f"{detail}; {detail2}"
                if not ok:
                    with print_lock:
                        print(f"Warning: worktree æ¸…ç†å¤±è´¥: #{issue_number}: {detail}", file=sys.stderr)

            # æ¸…ç†è¿œç¨‹åˆ†æ”¯
            ok_rb, detail_rb = _cleanup_remote_branch(issue_number, repo_dir, state)
            if not ok_rb:
                with print_lock:
                    print(f"Warning: è¿œç¨‹åˆ†æ”¯æ¸…ç†å¤±è´¥: #{issue_number}: {detail_rb}", file=sys.stderr)

        try:
            worktree_path = _create_worktree(worktree_script, issue_number, repo_dir, state)
            with state.lock:
                state.active_worktrees[issue_number] = worktree_path

            rc = _run_claude(issue_number, worktree_path, tty_stdin, state)
            if state.interrupted:
                final_status = "interrupted"
                final_returncode = rc
                break

            if rc == 0:
                pr_number = _get_pr_number(issue_number, repo, cwd=repo_dir, state=state)
                if pr_number:
                    observed_pr_number = pr_number
                    review_rc = _run_pr_review(pr_number, worktree_path, tty_stdin, state)
                    if review_rc != 0:
                        last_error = f"pr review exit={review_rc}"
                        attempt_details.append(f"attempt {attempt}: {last_error}")
                        final_returncode = review_rc
                    else:
                        ok, detail = _merge_pr(pr_number, repo, cwd=repo_dir, state=state)
                        if ok:
                            final_status = "completed"
                            final_returncode = rc
                            break
                        last_error = detail
                        attempt_details.append(f"attempt {attempt}: {detail}")
                else:
                    observed_pr_number = None
                    final_status = "completed"
                    final_returncode = rc
                    break
            else:
                last_error = f"claude exit={rc}"
                attempt_details.append(f"attempt {attempt}: {last_error}")
                final_returncode = rc

        except KeyboardInterrupt:
            state.interrupted = True
            final_status = "interrupted"
            break
        except Exception as e:
            last_error = str(e)
            attempt_details.append(f"attempt {attempt}: {e}")
        finally:
            if worktree_path:
                ok, detail = _remove_worktree(worktree_script, issue_number, repo_dir, state)
                if not ok and (force_cleanup or state.interrupted):
                    ok2, detail2 = _force_remove_worktree(issue_number, worktree_path, repo_dir, state)
                    if ok2:
                        ok, detail = True, ""
                    else:
                        detail = f"{detail}; {detail2}"
                if not ok:
                    with print_lock:
                        print(f"Warning: worktree æ¸…ç†å¤±è´¥: #{issue_number}: {detail}", file=sys.stderr)

            with state.lock:
                state.active_worktrees.pop(issue_number, None)

        if final_status == "completed" or state.interrupted:
            break

    elapsed_sec = time.monotonic() - issue_start
    detail = "\n".join(attempt_details).strip()
    if final_status == "failed" and not last_error:
        last_error = _last_nonempty_line(detail) or "-"

    # ä» state æ³¨é”€
    with state.lock:
        state.active_issues.discard(issue_number)

    result = IssueResult(
        number=issue_number,
        priority=priority,
        title=title,
        status=final_status,
        pr_number=observed_pr_number,
        elapsed_sec=elapsed_sec,
        attempts=attempts,
        returncode=final_returncode,
        detail=detail,
    )

    # æ‰“å°ç»“æœ
    with print_lock:
        if result.status == "completed":
            pr_text = f"ï¼ŒPR #{result.pr_number} å·²åˆå¹¶" if result.pr_number else ""
            print(
                f"âœ… Issue #{issue_number} å·²å®Œæˆ{pr_text} (è€—æ—¶ {_format_duration(result.elapsed_sec)})",
                flush=True,
            )
        elif result.status == "failed":
            print(
                f"âŒ Issue #{issue_number} å¤±è´¥ (å°è¯• {attempts}/{max_attempts}): {last_error}",
                flush=True,
            )

    return result


def _execute_batch_concurrent(
    batch_specs: list[IssueSpec],
    batch_priority: str,
    start_idx: int,
    total: int,
    repo: Optional[str],
    repo_dir: Path,
    worktree_script: Path,
    max_retries: int,
    force_cleanup: bool,
    tty_stdin: Optional[TextIO],
    state: ExecState,
    results: list[IssueResult],
    results_lock: Lock,
) -> int:
    """
    å¹¶å‘æ‰§è¡Œä¸€ä¸ªæ‰¹æ¬¡å†…çš„æ‰€æœ‰ issuesï¼ˆDAG è°ƒåº¦ï¼Œä¾èµ–æ„ŸçŸ¥ï¼‰ã€‚
    è¿”å›å®Œæˆçš„ issue æ•°é‡ã€‚
    """
    if not batch_specs:
        return 0

    prio_label = batch_priority.strip().upper() if batch_priority else "P2"

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–
    has_dependencies = any(spec.dependencies for spec in batch_specs)

    # è®¡ç®—è‡ªé€‚åº”å¹¶å‘æ•°
    max_workers = _calculate_max_workers(batch_priority, len(batch_specs), has_dependencies)

    print(f"ğŸ“¦ {prio_label} æ‰¹æ¬¡ ({len(batch_specs)} issues, å¹¶å‘={max_workers})", flush=True)

    # åˆ›å»º DAG è°ƒåº¦å™¨
    scheduler = DagScheduler(batch_specs)
    print_lock = Lock()
    batch_completed = 0
    current_idx = start_idx

    # åˆ›å»º issue number -> spec æ˜ å°„
    spec_map = {s.number: s for s in batch_specs}
    # åˆ›å»º issue number -> idx æ˜ å°„
    idx_map = {}
    for i, spec in enumerate(batch_specs):
        idx_map[spec.number] = start_idx + i

    def execute_issue(issue_num: int) -> IssueResult:
        """æ‰§è¡Œå•ä¸ª issue çš„åŒ…è£…å‡½æ•°"""
        spec = spec_map[issue_num]
        idx = idx_map[issue_num]
        return _execute_single_issue(
            spec=spec,
            idx=idx,
            total=total,
            prio_label=prio_label,
            repo=repo,
            repo_dir=repo_dir,
            worktree_script=worktree_script,
            max_retries=max_retries,
            force_cleanup=force_cleanup,
            tty_stdin=tty_stdin,
            state=state,
            print_lock=print_lock,
        )

    # ä½¿ç”¨ ThreadPoolExecutor å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures: dict[int, Any] = {}  # issue_number -> Future

        while not scheduler.is_done() and not state.interrupted:
            # è·å–å¯ä»¥å¼€å§‹çš„ issues
            ready_issues = scheduler.get_ready_issues()

            # æäº¤æ–°ä»»åŠ¡
            for issue_num in ready_issues:
                if issue_num not in futures and scheduler.mark_started(issue_num):
                    future = executor.submit(execute_issue, issue_num)
                    futures[issue_num] = future

            # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
            completed_futures = []
            for issue_num, future in list(futures.items()):
                if future.done():
                    completed_futures.append((issue_num, future))

            for issue_num, future in completed_futures:
                try:
                    result = future.result()
                    with results_lock:
                        results.append(result)

                    if result.status == "completed":
                        scheduler.mark_completed(issue_num)
                        batch_completed += 1
                    else:
                        scheduler.mark_failed(issue_num)
                except Exception as e:
                    # å¼‚å¸¸æƒ…å†µï¼Œæ ‡è®°ä¸ºå¤±è´¥
                    scheduler.mark_failed(issue_num)
                    with print_lock:
                        print(f"âŒ Issue #{issue_num} æ‰§è¡Œå¼‚å¸¸: {e}", file=sys.stderr)

                del futures[issue_num]

            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«é˜»å¡çš„ issues
            blocked = scheduler.has_blocked_issues()
            if blocked and not futures and not ready_issues:
                # æ‰€æœ‰å¯æ‰§è¡Œçš„éƒ½å®Œæˆäº†ï¼Œä½†è¿˜æœ‰è¢«é˜»å¡çš„
                with print_lock:
                    blocked_nums = " ".join(f"#{n}" for n in blocked)
                    print(f"âš ï¸ ä»¥ä¸‹ issues å› ä¾èµ–å¤±è´¥è€Œè·³è¿‡: {blocked_nums}", flush=True)

                # æ ‡è®°è¢«é˜»å¡çš„ issues ä¸º skipped
                for issue_num in blocked:
                    scheduler.mark_failed(issue_num)
                    spec = spec_map[issue_num]
                    with results_lock:
                        results.append(IssueResult(
                            number=issue_num,
                            priority=spec.priority,
                            title=spec.title,
                            status="skipped",
                            detail="ä¾èµ–çš„ issue å¤±è´¥",
                        ))
                break

            # çŸ­æš‚ä¼‘çœ é¿å… CPU å ç”¨è¿‡é«˜
            if futures:
                time.sleep(0.1)

        # ç­‰å¾…æ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡å®Œæˆï¼ˆä¸­æ–­æ—¶ä¹Ÿè¦ç­‰å¾…ï¼‰
        for issue_num, future in futures.items():
            try:
                result = future.result(timeout=1.0)
                with results_lock:
                    results.append(result)
                if result.status == "completed":
                    batch_completed += 1
            except Exception:
                pass

    if not state.interrupted:
        print(f"ğŸ“¦ {prio_label} æ‰¹æ¬¡å®Œæˆ ({batch_completed}/{len(batch_specs)})", flush=True)

    return batch_completed


def main() -> None:
    parser = argparse.ArgumentParser(description="æŒ‰ priority æ‰¹æ¬¡å¹¶å‘æ‰§è¡Œ Issuesï¼ˆworktree + claudeï¼‰")
    parser.add_argument("--input", help="priority_batcher.py --json çš„è¾“å‡ºæ–‡ä»¶ï¼ˆé»˜è®¤ä» stdin è¯»å–ï¼‰")
    parser.add_argument("--repo", help="ç”¨äº gh issue view çš„ä»“åº“ï¼ˆé»˜è®¤ä½¿ç”¨å½“å‰ä»“åº“ï¼‰")
    parser.add_argument("--repo-dir", default=".", help="æ‰§è¡Œ git/gh/worktree çš„ä»“åº“ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰")
    parser.add_argument(
        "--worktree-script",
        default=str(DEFAULT_WORKTREE_SCRIPT),
        help="worktree.py è„šæœ¬è·¯å¾„",
    )
    parser.add_argument(
        "--force-cleanup",
        action="store_true",
        help="æ¸…ç† worktree å¤±è´¥æ—¶ï¼Œå°è¯•ä½¿ç”¨ git worktree remove --force",
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=3,
        help="æ¯ä¸ª issue å¤±è´¥åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰",
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=0,
        help="è¦†ç›–è‡ªé€‚åº”å¹¶å‘æ•°ï¼Œ0 è¡¨ç¤ºä½¿ç”¨è‡ªé€‚åº”è®¡ç®—ï¼ˆé»˜è®¤ 0ï¼‰",
    )
    args = parser.parse_args()

    repo_dir = Path(args.repo_dir).expanduser().resolve()
    worktree_script = Path(args.worktree_script).expanduser().resolve()

    if args.max_retries < 0:
        print("Error: --max-retries å¿…é¡» >= 0", file=sys.stderr)
        sys.exit(2)

    if not worktree_script.exists():
        print(f"Error: worktree.py ä¸å­˜åœ¨: {worktree_script}", file=sys.stderr)
        sys.exit(1)

    state = ExecState()
    results: list[IssueResult] = []
    results_lock = Lock()
    tty_stdin = _open_tty_stdin()

    def _handle_sigint(_signum, _frame):
        state.interrupted = True
        # å‘æ‰€æœ‰æ´»è·ƒè¿›ç¨‹å‘é€ SIGINT
        with state.lock:
            for proc in state.active_processes.values():
                if proc and proc.poll() is None:
                    try:
                        proc.send_signal(signal.SIGINT)
                    except Exception:
                        pass
        raise KeyboardInterrupt

    signal.signal(signal.SIGINT, _handle_sigint)

    data = _read_json_input(args.input)
    upstream_warnings = data.get("warnings")
    if isinstance(upstream_warnings, list):
        for w in upstream_warnings:
            if isinstance(w, str) and w.strip():
                print(f"Warning: {w.strip()}", file=sys.stderr)
    specs, warnings = _extract_specs(data)
    if warnings:
        for w in warnings:
            print(f"Warning: {w}", file=sys.stderr)

    total = len(specs)
    if total == 0:
        _print_report([], interrupted=False)
        return

    print(f"ğŸš€ å¼€å§‹å¤„ç† (å…± {total} ä¸ª issues)", flush=True)

    # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
    batches: list[tuple[str, list[IssueSpec]]] = []
    for spec in specs:
        priority = spec.priority or "p2"
        if not batches or batches[-1][0] != priority:
            batches.append((priority, [spec]))
        else:
            batches[-1][1].append(spec)

    try:
        idx = 1
        for batch_priority, batch_specs in batches:
            if state.interrupted:
                break

            # å¹¶å‘æ‰§è¡Œæ‰¹æ¬¡
            _execute_batch_concurrent(
                batch_specs=batch_specs,
                batch_priority=batch_priority,
                start_idx=idx,
                total=total,
                repo=args.repo,
                repo_dir=repo_dir,
                worktree_script=worktree_script,
                max_retries=args.max_retries,
                force_cleanup=args.force_cleanup,
                tty_stdin=tty_stdin,
                state=state,
                results=results,
                results_lock=results_lock,
            )

            idx += len(batch_specs)

    except KeyboardInterrupt:
        state.interrupted = True
        # æ¸…ç†æ‰€æœ‰æ´»è·ƒçš„ worktrees
        with state.lock:
            for issue_num, worktree_path in list(state.active_worktrees.items()):
                _force_remove_worktree(issue_num, worktree_path, repo_dir, state)

    finally:
        if tty_stdin:
            try:
                tty_stdin.close()
            except Exception:
                pass
        _print_report(results, interrupted=state.interrupted)

    if state.interrupted:
        sys.exit(130)
    if any(r.status == "failed" for r in results):
        sys.exit(1)


if __name__ == "__main__":
    main()
